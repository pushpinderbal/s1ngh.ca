---
layout: post
title:  "AWS SAA-C02"
author: "Pushpinder"
date:   2022-01-01 07:19:51 +0000
tags: ["certification", "aws"]
---

Each AWS account has a unique account root user with a unique email address.
Initially the account root user is the only user created. It has full access to everything inside the account and **can't be restricted.**

AWS is a Pay-As-You-Go Platform.

IAM can be used to create multiple different identities inside an AWS account. All identities start with no access to any resources in the account but can be given ALL or LIMITED permissions. Cross account permissions can be set using IAM identities. IAM identities start with no permissions and they have to be explicitly assigned.

By default all access to an AWS account and resources is denied except for the account root user. External identities can be explicitly granted access.

Multiple AWS accounts can be linked together using AWS organizations.

Best practice to create IAM admin instead of using the root account.

***aws configure --profile <span style="text-decoration: underline;">profile-name</span>*** : Setup a named profile.

***aws s3 ls --profile <span style="text-decoration: underline;">profile-name</span>*** : Perform s3 ls operation in the specified named profile account.

## **Cloud Computing Fundamentals**

**Characteristics:**

<p class="callout info">IMPORTANT FOR EXAM ANSWER IDENTIFICATION</p>

1. On-Demand Self-Service - Provision and terminate using a UI/CLI without human intervention.
2. Broad Network Access - Access services over any networks, on any devices, using standard protocols and methods.
3. Resource Pooling - Economies of scale, cheaper service.
4. Rapid Elasticity - Scale UP (OUT) and DOWN (IN) automatically in response to system load.
5. Measured Service - Usage is measured. Pay for what you consume.

<table border="1" id="bkmrk-public-cloud-private" style="border-collapse: collapse; width: 100%; height: 74px;"><tbody><tr style="height: 45px;"><td style="width: 25%; height: 45px;">Public Cloud</td><td style="width: 25%; height: 45px;">Private Cloud</td><td style="width: 25%; height: 45px;">Multi Cloud</td><td style="width: 25%; height: 45px;">Hybrid Cloud</td></tr><tr style="height: 29px;"><td style="width: 25%; height: 29px;">Cloud environment that's available to the public. They meet the 5 essential characteristics of cloud computing.</td><td style="width: 25%; height: 29px;">Dedicated cloud that can be run from business premises. Difference between private cloud and traditional on-premise setup is that the private cloud still has to follow the 5 characteristics. </td><td style="width: 25%; height: 29px;">Using multiple cloud environments. For example, using AWS and Azure for a service.

Cloud provider level resilience.

Multiple clouds could be managed through a third party tool, however it would limit functionality to the common features avaialble.

</td><td style="width: 25%; height: 29px;">Using private cloud and public cloud in conjunction.

</td></tr></tbody></table>

Hybrid environment means using public cloud in conjunction with on-premises setup.

**Service Models**

- On-Premises
- DC Hosted
- IAAS
- PAAS
- SAAS

## **AWS Fundamentals**

Private and Public Services are all about **networking**. The difference between public and private service is networking, meaning if there's connectivity. An AWS public service is one which can be connected from anywhere with internet.

Connectivity doesn't mean permissions. even if a service is publicly accessible, the client may require separate permissions to access the service.

By default no connections are allowed between the public and private network. Three zones: **Public Internet, AWS Public, AWS Private.**

Services in the private zone can be accessed publicly by projecting part of them in the public zone. Private services can be access only from the same private network, or from other networks explicitly configured.

**AWS Regions -** A full deployment of AWS infrastructure. Regions are geographically spread. When you are interacting to an AWS service, you are doing that in a specific location, for example. EC2 is N. Virginia is separate than EC2 in Sydney.

**AWS Edge Locations -** Local distributions points. More widespread.

Some AWS services are like their own individual deployments in different regions, while some are global services, such as IAM.

[https://www.infrastructure.aws/](https://www.infrastructure.aws/)

Need to allow AWS to share data between different regions.

**Availability Zone -** Inside every region there are multiple availability zones. Isolated compute, storage, networking, power and facilities.

An availability zone could be one datacenter or multiple datacenters. It's isolated from each of the other AZ's and configured with high speed links.

**Global Resilient -** Same service running at all regions across the globe.

**Regions Resilient -** Same service running from multiple availability zones in a region.

**AZ Resilient -** Services running from single availability zone. Very prone to failure.

**VPCs** are regional services operating from multiple AZs in a region.

**Default VPC -** 1 per region, initially crated by AWS. Pre-Configured in a very specific way and all configuration is handled by AWS. It can be removed and re-created. Some service in AWS assume the default VPC to be present.

**Custom VPC** - Not Limited

Default VPC are only assigned one CIDR address which is same in all regions --&gt; 172.31.0.0/16

Custom VPC can have multiple CIDR assignments.

The default VPC is configured to have one subnet in each AZ.

Anything placed in the default VPC subnets is assigned a public IPv4 address. A default VPC comes with an **Internet Gateway, Network ACL** and **Security Group.**

**EC2 - IAAS** - Provides Virtual Machines. Unit of consumption is IAAS. It's a private service by default. EC2 instance runs in a specific subnet of VPC. EC2 instances are AZ resilient.

EC2 instances can use local host storage or EBS.

Instance State - **Running -&gt; Stopped -&gt; Terminated.** Terminated means deletion and is irreversible.

 A stopped instance still generates storage charges. The only way to eliminate all resource charges is to terminate the instance.

An AMI(Amazon Machine Image) can be used to create an EC2 instance and EC2 can be used to create an AMI.

AMI maintains --&gt; Permissions, Root Volume, Block Device Mapping

RDP - Port 3389

One security group can apply to many network interfaces on multiple instances.

System status checks - This check verifies that your instance is reachable. Amazon EC2 tests that network packets can get to your instance. If this check fails, there might be an issue with the infrastructure that is hosting your instance (such as AWS power, networking, or software systems). You can restart or replace the instance, wait for Amazon EC2â€™s systems to resolve the issue, or seek technical support. This check does not validate that your operating system and applications are accepting traffic.

Instance status checks - This check verifies that your instance's operating system is accepting traffic. If this check fails, you might need to reboot your instance or modify the configuration of your instance's operating system

S3 is a global storage platform. It is regional based and region resilient.

**S3 is a public service,** meaning it can be accessed from anywhere with internet access.

S3 objects - Key:Value . Value of S3 object can range from 0 bytes - 5TB.

Objects also have a version ID, metadata, access control and sub resources.

Buckets are created in a specific AWS region. Data never leaves that region unless configured. Stable and controlled data sovereignty. Blast radius is the region. A bucket name needs to be globally unique unlike most other AWS resources which need to be unique only in an account.

<p class="callout info">All objects are stored in the bucket at the root level. Folders are represented when a file has a name such as /folder/fil and the UI shows them as folders. Folders are referred to prefixes. S3 is not a file or block storage system. All files are storage in a flat bucket. It has no file system. S3 cannot be mounted.</p>

Objects in buckets can be divided using prefixes. For an S3 Object, Key = Name, Value = Data.

**S3 should be the preferred storage platform for all AWS services.**

In bucket settings, the **Block all public access** acts like a fail-safe to disable public access. Un-checking this settings doesn't make the bucket publicly accessible as that has to be configured separately.

ARNs uniquely reference one resource in AWS.

**CloudFormation** is an Infrastructure as Code (IaC) product in AWS which allows automation infrastructure creation, update and deletion.

CloudFormation templates are created in YAML or JSON.

All CloudFormaiton templates have a **resources** section which define what resources need to be created. It is the only mandatory part in a template.

If **AWSTemplateFormatVersion** and **Description** are both included in a template, they must be entered in same order. **Description** **must follow AWSTemplateFormat Version.**

**Metadata** control the UI.

**Parameters** is where fields can be added where information is required from the user.

**Conditions** allow decision making in the template. A condition is first crated and then assigned to resources.

Resource definition are created for Logical Resources. Logical resources have a type which tell CloudFormation what kind of resource to create.

CloudFormation creates a stack(s) from the templates.

For any logical resource in the stack, CloudFormation creates a corresponding Physical Resource. It's cloud formation's job to keep the logical and physical resources in sync. A template can be updated to update the stack and the related physical resources.

If a stack is deleted, it's logical and physical resources are deleted.

When uploading templates to CF, it creates a S3 bucket to store the template file with a prefix cf. These can be deleted.

**Cloudwatch** provides --&gt; Metrics, CloudWatch Logs, CloudWatch Events.

CloudWatch namespace is a container for monitoring data. All AWS data goes into a namespaces usually named by AWS/*service\_name*, such as AWS/EC2

A metric is a collection of related data points in a time ordered structure. A datapoint can be considered as a measurement, it consists of a timestamp and value.

Cloudwatch Alarms are linked to metrics, and take actions based on criteria from metrices. States of Alarm --&gt; OK, Alarm, Insufficient Data.

All EC2 instances by default have cloudwatch enabled for 5-minutes periods. Enabling details monitoring allows 1-minute period logs(paid).

To set an alarm for CPU utilization, in cloud watch, create an alarm, in metric enter the instance ID. Set a static threshold with a condition.

AWS is responsible for security **of** the cloud. Customers are responsible for security **in** the cloud.

**High-Availability(HA) -** Aims to ensure an agreed level of operation performance. **Does not mean that there will be no downtime/failure. A highly available system is one designed for fast/automatic recovery. It is not about the user experience. It's about maximizing online time.**

**99.9%** downtime - 8.77 hours p/year downtime.

**99.999%** downtime - 5.26 minutes p/year downtime

For high availability, user disruption is **OK.**

**Fault-Tolerance(FT) -** Enable a system to continue operating properly in the event of a failure. Systems are designed to work through failure with no disruption.

Fault tolerance can be expensive and harder to design than HA due to additional resource requirement. Fault Tolerance first means ensuring HA, and then system designing for FT.

Systems can be designed for HA or FT.

**Disaster Recovery(DR)** **-** Enable recovery or continuation of vital technology infrastructure and systems following a natural or human-induced disaster. This comes into play when the HA or FT options have been consumed. Requires pre-planning for DR process.

**Route53** allows domain registration and host zones. Its' a **global service** and has a single database. Globally resilient service.

A hosted zone on Route53 can be public or private(linked to VPCs).

## **IAM, Accounts and AWS Organizations**

IAM policy is a set of security statements on AWS. It grants or denies access to services to the linked identities. A policy document contains one or more statements. A statement only applies if the attempted interaction matches the action and the resource specified in the statement. The action part match one or more actions. Wildcards can also be used.

**Actions** can be, individual actions, wildcards, or a list of actions. **Resource** refers to a service or object that is being access in the interaction, for example an S3 object. **Effect** controls what the policy does if the action and resource match.

First priority is **explicit deny.** Second priority is **explicit allow.** If you are explicitly allowed and denied access simultaneously, the **explicit deny always takes priority.** Default policy is implicit deny except the root account. Nothing has access to anything unless otherwise specified.

**DENY --&gt; ALLOW --&gt; DENY(IMPLICIT)**

When a give identity accesses a resource, AWS collects all the statements in all of the policies that apply and evaluates them **all at the same time.**

Inline policy refers to individual policies assigned to each identity.

Managed policies are reusable and can used on multiple identities at the same time. Should be used for normal default access rights. Inline policies are for special or exceptional rights.

Managed policies are of two types: AWS Managed, and Customer Managed.

IAM starts with a principal, which is an identity trying to authenticate. A principal needs to be authenticated and authorized in order to do anything.

Principal authentication is done through username/password or access keys. Upon authentication, it is an authenticated identity, and AWS knows what policies apply to this identity, the process of authorization.

**Amazon Resource Name(ARN) -** Uniquely identify resources within any AWS account.

<p class="callout warning">**arn:aws:s3:::catgifs - Refers to the bucket**</p>

<p class="callout warning">**arn:aws:s3:::catgifs/\* - Refers to objects in the bucket**</p>

<p class="callout warning">**Both of the above are different and do not overlap.**</p>

In an arn for S3, account and region id can be omitted. Skipping the region and using a \* wildcard are two different things.

- 5000 IAM Users per account
- One IAM user can be a member of 10 groups

Generally, federated identity services are used for environment requiring higher numbers of users.

IAM Groups are containers for Users. The IAM groups have no credentials and cannot be logged into. They are used for user management.

An IAM user can be a member of multiple groups. Groups can have inline or managed policies attached.

Groups cannot be nested.

AWS resources can have policies configured on them to grant access to IAM users and roles as principals. Groups are **not a true identity, so they can't be referenced as a principal in a resource policy. Groups are just there to group users and apply direct policies to groups.**

A principal is a user, device, service account or process. IAM users identify a single principal.

If the number of principal is uncertain, IAM roles is the preferred identity. IAM roles are assumed. It represents a level of access inside an AWS account, it can be used for short term by identities. Roles can be granted to multiple identities/users.

IAM Roles have **Trust Policies and Permissions Policies.** Trust policies define the identities which are allowed to assume that role, it can refer account in same plus different accounts. If a role is assumed, temporary security credentials are created for the user assuming the role. These temporary credentials define the permissions assigned to those credentials.

Roles are used in AWS to login to one account and allow usage of different accounts from there.

Temporary credentials are generated by sts(Secure Token Service), the role used is **sts:AssumeRole**.

**Example of IAM Role usage:**

- Using a Lambda Execution Role for running a Lambda function. Instead of hard-coding access keys from an IAM user to the Lambda function, IAM role can be assigned, so it gets temporary credentials from sts:AssumeRole and applies the assumed permission policy.
- Emergency Roles can be used
- Roles can be used for external identities, such as SSO or when the users are more than 5000. **External accounts can't be used in AWS directly.** Role is assumed by the external identity and gets access to the AWS resource.
- Cross-Account access

Always better for AWS products and services to use IAM roles.

AWS Organization allow large organizations to manage multiple accounts. A standard account is used to create the organization, this accounts then becomes the management/master account of the organization. Existing standard AWS accounts can be invited to the organization, these accounts will then become member accounts of the organization. Organizations have **one** master/management account.

Organization root container contains other member/management accounts or other OUs. OUs have their own member and management/master accounts.

Joining an organization consolidates accounts' billing.

Using organization, AWS usage benefits are pooled. Service Control Policies restrict AWS accounts.

New accounts can also be created directly in an AWS organization. With organizations IAM roles can be used to access other member accounts.

In organization setups, best architecture pattern would be to use one account for identity management, and then configure IAM roles to allow access to other account. This account can also be used with identity federation. Access is gained to the identity management account and role switch is used to access other member accounts.

When a new account is created in an organization, the role for **role switch** is automatically created, however with existing accounts the role needs to be added manually.

![](https://s1ngh.ca/images/image-1611718148651.png)

**Service Control Policies** are a feature of AWS organization which allows restrictions to be placed on members accounts. SCPs can be applied to the organization, to OU's or to individual accounts. They are inherited down the organization tree. Management cannot be effected by SCPs.

The account root user cannot be restricted, however with SCPs, accounts can be limited which would automatically limit the priveleges of the account root user.

<p class="callout danger">**SCPs don't grant permissions, but only define what is allowed and not allowed in an AWS account.**</p>

In AWS Organization, enable SCP and then new policies can be created. To attach SCP to an OU, go to organize accounts and attach the SCP. The default SCP allows FullAccess.

CloudWatch is a public service. Some AWS services have built in intergrations with CloudWatch where they can log data, access is generally granted through IAM roles for these services. Services that do not have built in integrations can be set up with the **Unified Cloudwatch agent.**

Cloudwatch is a regional service.

A log stream is an ordered set of log events for a specific source in a service, for example, one stream for each EC2 instance. A log groups contains multiple log streams.

Retention/Permissions and Metric Filter are set on Log Groups.

CloudTrail logs API actions that affect AWS accounts. It logs API calls/activites as a CloudTrail Event. By default 90 days are stored in Event History.

To enable more duration than 90 days, need to create **Trails**.

Management Events - Control Plane Operations

Data Events - Resource related events.

By default only managements events are logged.

CloudTrail is a regional service. Services create log in the regions they are located in. Global services always log their events to us-east-1.

A trail can be in a single region or in all regions. The trail captures all management and data events(if enabled). Trails store files in S3 bucket.

CloudTrail can put all the generated data in CloudWatch logs. This allows better viewability through CloudWatch. A trail can be created on the master account and configured to log events across all accounts

<p class="callout info">s3 storage for CloudTrail is only enabled when a trail is created. By default, only management events are logged. IAM, STS, CloudFront are classified as true global services and they log their data as global service events. **The CloudTrail log is not realtime**, there is a delay for the data to arrive in S3 or CloudWatch Logs.</p>

Organizational trails can be created only from the management account, this is the efficient method instead of creating individual trails in all accounts.

## **S3**

S3 is private by default. Buckets can be configured with resource policies. Unlike identity policies, resource policies can allow/deny same or different accounts.

Resource policies can allow/deny anonymous principals.

Resource policies have an additional definition as compared to identity policies, the **Principal. For an internal identity, the effective access is determined from the resource policies plus identity policies. For anonymous access, only resource policies are applied. For cross-account access, resource policies along with the identity's policies from the other account apply. Therefore, for cross-account access, policies on both accounts matter.

Access Control Lists are a sub-resource of objects and buckets. **Legacy**.

![](https://s1ngh.ca/images/image-1611725362879.png)

Static website hosting on S3 can be used for Offloading websites and for serving out of band pages.

To do static website hosting, enable Static website hosting in the bucket properties, allow GetObject to \* principal.

A Route53 DNS name can be used for the S3 website, by naming the bucket same as the website FQDN, then in Route 53 crate a simple record and in that an alias to the bucket.

Object versioning cannot be disabled after enabling it on a bucket. It can be suspended and then enabled back.

Versioning lets you store multiple versions of objects within a bucket. When versioning of a bucket is disabled, the object id is set to null. Enabling versioning sets an object id. Versions can be accessed by specifying the id. Deleting an versioning enabled object just adds a delete marker on top of the versions, so technically just hiding the old versions. The delete marker can be deleted to get the objects back. To actually delete the object, the object version needs to be specified. All object versions consume space. Suspending versioning on a bucket only stops new versions from being created. Only way to eliminate all costs from versioning is to completely delete the bucket.

MFA Delete is enabled in versioning configuration. It means the MFA is required to change the bucket versioning state plus to delete versions of an object.

By default data is uploaded in a single data stream to S3. If the stream fails the whole uploads fails, so the only recovery is to do a full restart. Single PUT upload allows upto 5GB data upload.

In multipart uploads, the data is broken up, minimum size is 100MB for multipart, therefore for any data lower than the threshold multipart upload cannot be used. An upload can be split in upto 10000 max parts, with each of 5MB-5GB, last part can be smaller than 5GB. Parts can fail and be restarted.

S3 transfer acceleration can be used to transfer data through AWS edge locations. The AWS edge locations can then transfer data to an S3 bucket with the most reliable and higher performing connections. To enable S3 transfer acceleration, a bucket name cannot contain some special characters and needs to be DNS compliant.

Enabling transfer acceleration creates a new bucket endpoint which must be used.

**Key Management Service (KMS)** regional and public service. It is used to create, store and manage keys. It can store symmetric and asymmetric keys. Keys never leave KMS. It's primary function is to ensure that the keys are secure. **FIPS 140-2 (L2)** Compliant.

KMS manages customer master keys (CMK). It's like a container for a key. The container contains ID, physically backed, etc.. CMKs can only be used to directly encrypt or decrypt data upto 4KB of data.

KMS creates an encrypted key from a CMK. When data is to be encrypted, it decrypts the CMK from the encrypted key and uses it for data encryption, same follows for decryption of data. At no point does the key leave KMS.

**Data Encryption Keys (DEKs)** are another types of keys generated in KMS from a CMK using a GenerateDataKey. These keys work on data greater than 4KB. KMS doesn't store DEK, and it doesn't use it for anything beyond initial generation.

KMS generates a plaintext version and a ciphertext version(encrypted with CMK) for a DEK. From an architectural perspective, the plaintext version should be used to encrypt the data and then discarded. The data can then be store along with the encrypted key, and when needed the encrypted key can be decrypted using the corresponding CMK. The decrypted DEK can then be used to decrypt the data. Services like S3, use a new DEK for encrypting every object, and discard the plaintext version after encryption.

CMKs are isolated to a region and never leave. Two types of CMKs: AWS Managed(Automatically created when using AWS services) and Customer Managed(Explicitly created). CMKs support rotation. AWS managed keys are rotated every 3 years. CMK contains current as well as old backing keys. Aliases can be used for CMKs. Every CMK has a key policy. These policies are required to set up trust between KMS and AWS accounts.

Key policies can be used with IAM policies to define the KMS actions allowed/denied to users.

{% highlight shell %}
aws kms encrypt \
    --key-id alias/catrobot \
    --plaintext fileb://battleplans.txt \
    --output text \
    --query CiphertextBlob \
    --profile iamadmin-general | base64 \
    --decode > not_battleplans.enc
{% endhighlight %}

{% highlight shell %}
aws kms decrypt \
    --ciphertext-blob fileb://not\_battleplans.enc \ 
    --output text \
    --profile iamadmin-general \
    --query Plaintext | base64 --decode &gt; decryptedplans.txt

{% endhighlight %}

Buckets are not encrypted, **Object are.** S3 is capable of supporting client-side and server-side encryption(**at rest**).

Client-side encryption happens on the client side, before the data even being in transit to S3. S3 sees only encrypted data. Server-side encryption, data is encrypted by S3. All keys processing tooling has to be taken care of by the client in Client-side enc.

**SSE-C:** Server-Side Encryption with Customer-Provided Keys. Object is sent to S3 along with key. S3 encrypts the object, creates and links a hash of the key to the object and discards the key. To decrypt, the object identity and key is provided, S3 checks if the hash matches the provided key to verify the correct key is provided.

**SSE-S3(AES256):** Server-Side Encryption with Amazon S3-Managed Keys. Only unencrypted object is provided. S3 creates a master key which is same all across S3. For every object a new key is generated. Object is encrypted with the key, and the key itself is encrypted with the master key. Unencrypted key is discarded. S3 stores the encrypted data and the encrypted/ciphertext key together. Provides very little control over the keys, no role separation. **Default** type of encryption for most type of situations.

**SSE-KMS:** Server-Side Encryption with CMKs stored in KMS. S3 creates an AWS managed CMK, the default master key. CMK generates a unique DEK for every object. Can also use customer managed CMK. This provides **role separation.**

In a PUT operation the **x-amz-server-side-encryption** header enables server side encryption. This header can be set as AES256 or aws:kms. The bucket default encryption is the type of encryption applied to an object when nothing is specified.

**S3 Storage Classes:**

- **S3 Standard**
- **S3 Standard-IA**(Infrequent access)
- **S3 One Zone-IA**
- **S3 Glacier** - Objects stored as cold objects. Objects are stored in S3 Standard-IA temporarily for access.
- **S3 Glacier Deep Archive** - Data in frozen state.
- **S3 Intelligent-Tiering** - Objects can be stored in multiple tiers. Objects are moved between tiers automatically based on the monitored usage. Only use the slows retrieval tiers when application can handle asynchronous access patterns.

Intelligent tiering is only good if there's data with changing access patterns.

S3 lifecycle configuration is a set of rules that apply to buckets or objects based of certain criteria. These can be transition actions(to transition objects between different storage classes) and expiration actions(to delete or prune objects). With this setup objects cannot be transitioned based on access(that's only achievable through Intelligent-Tiering). Transition flows only in a downward trend.

To transition automatically from S3 Standard to Standard-IA or One Zone-IA, the object has to be in S3 for a minimum of 30 days. The same rule cannot be used to do the transition to glacier type within 30days. Multiple rules can be used to do the multi-stage transition.

Lifecycle rules can be configured to delete previous versions on object-versioning enabled buckets.

**Cross-Region Replication**

**Same-Region Replication**

For replication, the buckets can be in the same or different AWS accounts. The S3 service uses an IAM role that allow access to the source and destination buckets. When the replication is in the same account, the IAM service is trusted therefore it has access to both the source and destination as long as it's defined in the corresponding policy. If the destination bucket is in a different AWS account, the IAM role is by default not trusted in the destination account. Therefore, a bucket policy is required to allow this IAM role from another account have access to the bucket.

**Replication Options:**

- All objects or a subset(by prefix or tags)
- Storage Class - default is to use the same class as source
- Ownership - default is the source account, this may be problematic when replicating different AWS account.
- Replication Time Control(RTC) - To keep the buckets in sync within 15mins.

**Replication Considerations:**

- Not retroactive &amp; Versioning needs to be ON on source and destination - Will only replicate the objects which are added after turning on replication.
- One-Way replication (Source to Destination)
- Unencrypted, SSE-S3 &amp; SSE-KMS (with extra config)
- Cannot replicate objects with SSE-C
- **Source bucket owner needs permissions to objects.**
- Cannot replicate system events and objects stored in Glacier storage types.
- Deletes are not replicated.

**Why Replication:**

- SRR - Log Aggregation. If multiple buckets are used for services logs, they separate buckets can be replicated to one.
- SRR - PROD and TEST Sync.
- SRR - Resilience with strict sovereignty. Account level isolation while in the same region
- CRR - Global Resilience Improvements.
- CRR - Latency Reduction

S3 Presigned URLs are a feature of S3 which allows the system to generate a URL with access permissions encoded into it, for a specific bucket and object, valid for a certain time period.

A user can generate a presignedURL for a bucket. The presignedURL can be passed on to an un-authenticated user for access the bucket object. **presignedURL can be used for GET as well as PUT operations.**

![](https://s1ngh.ca/images/image-1612124147673.png)

- **You can create a URL for an object you have no access to, but the presigned URL will have no access(same as the creator).**
- **When using the URL, the permissions match the identity which generated it at the time of accessing the the URL.**
- **Access denied could mean the generating ID never had access or doesn't have now.**
- **Don't generate with a role. URL stops working when temporary credentials expire.**

When an object is opened from the console directly, the console adds authentication information to the link automatically.

`aws s3 presign s3://animals4lifemedia1313/all5.jpg --expires-in 180`

A pre-signed URL can be generated for a non-existent object. When a pre-signed URL is created with temporary credentials, the URL stops working when the pre-signed URL expires or if the temporary credentials expire, whichever happens first.

**S3 Select** and **Glacier Select** allow you to use a SQL-Like statement to retrieve partial objects from S3 and Glacier. The selected object is pre-filtered by S3.

![](https://s1ngh.ca/images/image-1612127010637.png)

**Amazon S3 notification** feature enables you to receive notifications when certain events happen in your bucket. To enable notifications, you must first add a notification configuration that identifies the events you want Amazon S3 to publish and the destinations where you want Amazon S3 to send the notifications. You store this configuration in the *notification* subresource that is associated with a bucket. Can be delivered to SNS, SQS and Lambda Functions. Can be notified on object create, delete, restore, replication. EventBridge is a superior alternative.

![](https://s1ngh.ca/images/C8dsc5PweMUGBafT-image-1640468610942.png)

Server access logging provides detailed records for the requests that are made to a bucket. Server access logs are useful for many applications. For example, access log information can be useful in security and access audits. It can also help you learn about your customer base and understand your Amazon S3 bill.

![](https://s1ngh.ca/images/oZQJNrJTAawa7JWR-image-1640468745242.png)

## **Virtual Private Cloud(VPC) Basics**

**VPC Considerations:**

- What size should the VPC be
- Are there any networks we can't use
- VPC's, Cloud, On-Premises, Partners &amp; Vendors
- Try to predict the future
- VPC Structure - Tiers &amp; Resiliency (Availability) Zones
- Reserve 2+ network per region being used per account.

In AWS, VPC **minimum /28 (16 IP), maximum /16 (65456 IPs)**.

![](https://s1ngh.ca/images/image-1612147238807.png)

Ideally, for each region set up networks for 3 availability zones and 1 spare zone along with tiered subnets for Web, App, DB, Spare, therefore 16 subnets per region.

- Regional Service - All AZs in the region
- Isolated network
- Nothing IN or OUT without explicit configuration.
- Hybrid networking - other cloud &amp; on-premises
- Default or Dedicated Tenancy - Controls whether the created resources in the VPC or created on shared or dedicated hardware. With default - this setting can be configured on a per resource basis.
- IPv4 Private CIDR Blocks &amp; Public IPs
- 1 Primary Private IPV4 CIDR Block
- Optional secondary IPv4 Blocks
- Optional single assigned IPv6 /56 CIDR Block

**DNS in a VPC:**

- Provided by R53
- VPC 'Base IP + 2' Address
- **enableDnsHostnames** - gives instance DNS Names if set to true
- **enableDnsSupport** - enables DNS resolution in VPC

Select VPC, Actions&gt;Edit DNS Hostnames to enable DNS hostname.

A subnet is an AZ resilient subnetwork of a VPC - within a particular AZ. 1 Subnet =&gt; 1 AZ, 1 AZ =&gt; 0+ Subnets. A subnet is assigned an IPv4 CIDR, subset of the VPC, and it cannot overlap with other subnets. Subnets can communicate with other subnets in the VPC. Isolation of a VPC is it its' perimeter.

**Reserved IP Addresses in a subnet (5 in total):**

- Network address
- Broadcast address
- 'Network +1' - VPC Router
- 'Network +2' - Reserved (DNS\*)
- 'Network +3' - Reserved future use

VPC is assigned a DHCP Options set. DHCP option sets can be created but not edited. Auto-assign public IPv4 and IPv6 address is set on a subnet basis.

**VPC Router**

- Every VPC has a VPC Router - Highly Available
- Routes traffic between subnets
- Controlled by 'route tables' each subnet has one
- A VPC has a main route table - subnet default. A subnet can have only one route table associated at any time, while a route table can be associated to multiple subnets.

In a route table, if multiple routes match from a routing table, the higher prefix is selected. The target decides where the traffic should be sent, Local routes always take priority.

**Internet Gateway (IGW)**

- Region resilient gateway attached to a VPC
- 1 VPC = 0 or 1 IGW, 1 IGW = 0 or 1 VPC.
- Runs from within the AWS Public Zone
- Gateways traffic between the VPC and the Internet or AWS Public Zone.
- Managed - AWS handles performance.

Public IPv4 addresses are created as a record on the IGW where it creates a mapping for the machine's private IP and the assigned public IP. At no point an OS in EC2 is aware of the public IPv4 address.

Bastion host = Jumpbox. An instance in a public subnet. Incoming connection arrive here, then access internal VPC resource. Often the only way in to a VPC.

- Create IGW
- Attach IGW to VPC
- Create Route tables and default routes
- Associate subnets to IGW
- Enable public IPv4 auto assignment for subnet

**Network Access Control (NACLs)**

Network Access Control Lists (NACLs) are a type of security filter (like firewalls) which can filter traffic as it enters or leaves a subnet. NACLs are attached to subnets and only filter data as it crosses the subnet boundary. NACLs are stateless and so see initiation and response phases of a connection and 1 inbound and 1 outbound stream requiring two roles (one IN one OUT).

Default NACL allows traffic in both directions.

- NACLS are stateless
- Only impacts data crossing subnet border
- Can explicitly allow and deny
- IPs/Networks, Ports &amp; Protocols - no logical resources
- NACLs cannot be assigned to AWS resources, only subnets.
- Use with SG's to add explicit DENY.
- One subnet = One NACL at a time. One NACL can be associated with multiple subnets but **not** vice-versa
- They are processed in order, starting with the lowest number.

**Security Groups (SG)**

Security Groups (SGs) are another security feature of AWS VPC ... only unlike NACLs they are attached to AWS resources, not VPC subnets.

SGs are stateful. They can reference AWS resources, such as EC2 instances, and even security groups. If in a SG rule, the source is the security group itself, it means anything the security group is attached to.

It has a hidden implicit deny. They cannot explicit deny. Can only allow specific traffic, so they often require NACL assitance.

- Stateful
- Can filter based on AWS logical resources
- Implicit Deny and Explicit Allow
- **No Explicit Deny**

![](https://s1ngh.ca/images/image-1612287153557.png)

**NAT Gateway**

Gives private CIDR range outgoing internet access. The NAT gateway does a many-to-one translation of multiple private IPs to it's own IP. The NAT gateway then forward the traffic to the Internet Gateway with it's own IP as source. The internet gateway translates the NAT gateways' IP to a public IP.

- Runs from a public subnet
- Uses Elastic IPs (Static IPv4 Public)
- AZ resilient service (HA in that AZ)
- For region resilience - NATGW in each AZ, route table in each AZ with that NATGW as target
- Managed, scales to 45 Gbps, $ Duration &amp; Data Volume

If need more bandwidth, can have multiple NAT gateways in the same AZ.

To implement a truly resilient architecture, each availability zone needs a NAT gateway with a private route table. The private route table will have a default route that points to it's NAT gateway.

If NAT instance is to be used, need to disable **Source/Destination** Checks, because by default an EC2 instance drops any traffic not purposed for it as the source/destination. Although one NAT gateway can be used in multiple AZs, this would make all the subnets fail if the NAT gateway goes down.

A NAT gateway cannot be repurposed for other services.

NAT gateways don't work with IPv6.

To add bidirectional connectivity for IPb6, add an IPv6 default route with the IGW as target.

## **Elastic Compute Cloud(EC2) Basics**

EC2 is an IaaS product.

- **Emulated Virtualization** - Running an host OS or a Hypervisor. Guest OS thinks it's running on a dedicated HW. Binary Translation done by the hypervisor.
- **Paravirtualization** - Similar to emulated virtualization. Guest OS is modified to run on the Host, makes hypercalls.
- **Hardware Assisted Virtualization** - Hardware(CPU) is virtualization aware but individual devices are not.
- **SR-IOV** - Hardware devices, like NICs are virtualization aware. Single-Route IO Virtualization. No translation has to happen by the Hypervisor. Guest OS can use the logical mini-cards directly. In EC2 this feature is called **Enhanced Networking.**

AWS Hypervisor Stack - **Nitro**

EC2 instances are virtual machines running on EC2 hosts (shared or dedicated). EC2 is AZ resilient ==&gt; AZ fails, host fails.

Instances can have multiple NICs in different subnets belonging to the same AZ. EC2 host can connect to EBS. EBS is also per AZ. EC2 host also has a temporary **Instance Store.**

Instances stay on the same host until the host fails or is removed, or if the instance is **stopped** and **started.** Instances cannot natively move between AZs. EBS or NIC of one AZ cannot be connected to from another AZ.

Generally, different types of instances may end up on different hosts. EC2 is suitable for monolithic application stacks. Pick EC2 as the default and only move away when there's a specific requirement.

**EC2 Categories**

- General Purpose **- Default**
- Computer Optimized - Media processing, HPC, scientific Modelling,
- Memory Optimized - Processing large in-memory datasets
- Accelerated Computing - Hardware GPU, FPGAs
- Storage Optimized - Sequential and Random IO.

Instance Type Naming - **Family-Generation-AdditionalCapabilities-.-Size**

[https://ec2instances.info](https://ec2instances.info)

AWS Instance connect uses AWS IAM permissions to login to the instance. EC2 instance connect is also restricted by security group rules. EC2 instance connect from the GUI only allows connecting to instances with public IP addresses.

[https://ip-ranges.amazonaws.com/ip-ranges.json](https://ip-ranges.amazonaws.com/ip-ranges.json)

{% highlight JSON %}
    {
      "ip_prefix": "18.206.107.24/29",
      "region": "us-east-1",
      "service": "EC2_INSTANCE_CONNECT",
      "network_border_group": "us-east-1"
    },
{% endhighlight %}

Instance Store is ephemeral storage. EBS is persistent storage.

**IO(Block) Size X IOPS = Throughput**

EBS Storage is provisioned in **ONE AZ**. Attached to one EC2 instance. Can be detached and re-attached. Persistent storage.

EBS snapshot backup can be performed into S3. Can create a new volume from a snapshot into a new AZ. EBS has different types, sizes and performance profiles. Billing is based on **GB/month**.

**Instance Store volumes are attached at launch time only.**

![](https://s1ngh.ca/images/vL2zFOYnHmyMNA8i-image-1634873799774.png)

EBS snapshots are incremental volume copies to S3.

Snapshots restore lazily from S3. Requested blocks are fetched immediately. Can force a read of all data immediately from the OS using a tool like **dd**. Fast Snapshot Restore(FSR) is an immediate restore feature now available, up to 50 snaps per region. FSR costs extra.

EBS charges for the allocated size. Snapshots only bill for the **used** data.

Stopping and Starting an EC2 instance leads to loss of data on the instance store volume. It also moves the instance from one host to another.

**EBS Encryption:** Uses KMS. CMK generates a DEK which is stored with the volume on the physical disk. DEK can only be decrypted using KMS. The decrypted copy of DEK is only stored in memory of the EC2 host. All the data on the physical disk is encrypted. DEK is discarded when instance is moved to another host. In this case, KMS needs to decrypt the DEK again and store in memory on the new host. Snapshots created from an encrypted volume share the same DEK, and subsequent volumes created from the same snapshot also use this DEK.

AWS accounts can be set to encrypt be default using default CMK**(aws/ebs)..** Can't change a volume to NOT be encrypted. OS isn't aware of the encryption. Volume is encrypted using AES256. Any other algorithms or key methods require OS level encryption.

All interfaces of the instance need to be in the same AZ.

Secondary interfaces can be detached and moved to other instances. The private DNS name is only resolvable inside the VPN. The public IP address is a public DNS record. Inside the VPC this record will resolve to the private IP of the primary NIC.

Elastic IP address is allocated to an AWS account. Assigning it to primary IP, the instance loses it's non-elastic public IP.

- Secondary ENI + MAC can help for cases of MAC based licensing.
- Different security groups - multiple interfaces.
- IPv4 public IPs are dynamic, unless they are elastic.
- Public DNS = private IP inside VPC, public IP everywhere else.

**AMI**

- AWS or Community Provided
- Marketplace (can include commercial software)
- AMI are regional and have a unique ID in each region.(eg, ami-*randomhex*)
- Permissions (Public, Your Account, Specific Accounts)

**AMI Lifecyle:** LAUNCH --&gt; CONFIGURE --&gt; CREATE IMAGE --&gt; LAUNCH

AMI is a container that references snapshots created from original EBS volumes along with original device IDs. Creating new instances from AMI will create instance with exactly the same device IDs.

- AMI is limited to a region.
- AMI baking =&gt; creating an AMI from a configured instance + application.
- AMI can't be edited. Can launch an instance, make changes, create new AMI.
- AMI can be copied between regions.
- AMI permissions.
- AMI costs for storage capacity used by snapshots of AMI.

**EC2 Purchase Options**

- **On-Demand:** Instances of different sizes runs on the same EC2 hosts. Per-second billing while instance is **running.** Default purchase option. No capacity reservation, no interruption, no upfront cost, no discount. Suitable for short-term and unknown workloads.
- **Spot:** AWS selling unused EC2 host capacity for up to 90% discount. Spot Price based on spare capacity at a given time. If spot price goes above maximum configured price, the instances are terminated. Never use for Workloads that cannot tolerate interruptions.
- **Reserved:** Long-term consistent use. Reduced price. Unused reservation is still billed. Reservations also have partial coverage of larger instance. Reservation for 1 year or 3 years terms. Pay all upfront(no per/s Fee) or no upfront(per/s Fee) or partial upfront(reduced per/s Fee).
- **Dedicated Hosts:** Pay for the host, no instance charges. Host affinity links instances to hosts. Useful for licensing based on sockets/cores. Need to monitor resource consumption and capacity.
- **Dedicated Instances:** Dedicated hardware not shared with other customer, but hardware is managed by AWS. Extra cost.

**Reserved Instances**

- Standard
- Scheduled Reserved Instances: Reserved on a schedule basis. Minimum term 1-year.

Reserved&gt;On-Demand&gt;Spot.

Regional reservation provides a billing discount for valid instances launched in any AZ in that region. They don't reserve capacity within an AZ.

Zonal reservations only apply to one AZ providing billing discounts and capacity reservation in that AZ.

On-demand capacity reservation can be booked to ensure you always have access to capacity in an AZ when you need it, but at full on-demand price. No term limits.

![](https://s1ngh.ca/images/lOwuEmMF4Ky9fPzZ-image-1638047029850.png)

EC2 Savings Plan: hourly commitment for a 1 or 3 year term. Can make a reservation of general computer $ amounts, or a specific EC2 savings plan. Beyond commitment of the savings plan, on-demand rate is applied.

**Instance Status Checks** - System status(EC2 service/host) and Instance status(OS Kernel/Networking/File System).

Instance can be enabled with 'Status Check Alarm' to auto-recover. Shutdown action can be changed to "Terminate". Terminate protection can be enabled by modifying **DisableApiTermination** setting.

**Vertical Scaling:** Adding resources to existing infrastructure. Requires downtime/reboot usually. Is easier to perform.

**Horizontal Scaling:** Adding new infrastructure. No downtime, however application needs to be aware of horizontal scaling. Sessions are an important piece.

Instance Metadata is accessible from any instance at: [http://169.254.169.254/latest/meta-data](http://169.254.169.254/latest/meta-data). No encryption or authentication while accessing this.

## **Containers &amp; ECS**

ECS allows running containers on AWS infrastructure, it's a managed container-based compute service. Two modes: **EC2** , **Fargate**.

ECS creates a ECS cluster where containers run from. AWS container registry is called Elastic Container Registry(ECR).

- **Container Definition** is created. Exposed ports, image, etc.
- **Task Definition** represents an application. Example, multiple containers(web+DB) for an application. Store the mode and the task role.
- **Task roles** are used to give ECS permissions to access AWS resources.
- **Service Definition** defines a task scalability and HA.
- The services are deployed in the ECS Cluster.

**ECS Cluster Types**

- **EC2:** EC2 instances are used to run containers. EC2 instances run in an auto-scaling group. Customer is responsible for managing the capacity and availability of container host. Billed even if no containers are running on the container host.
- **Fargate:** Serverless cluster mode. Containers are hosted on Fargate Shared Infrastructure. Tasks are injected into VPC by adding an elastic NIC. Billed only for the containers based on the resources consumed.

Selecting between EC2, ECS(EC2) and Fargate: If containers are already being used =&gt; ECS. Large workload/price conscious =&gt; EC2 Mode. Large workload/overhead conscious =&gt; Fargate. Small/Burst Workloads =&gt; Fargate. Batch/Periodic Workloads =&gt; Fargate.

## **Advanced EC2**

EC2 Bootstrapping is the process of configuring an EC2 instance to perform automated install &amp; configuration steps 'post launch' before an instance is brought into service. With EC2 this is accomplished by passing a script via the User Data part of the Meta-data service - which is then executed by the EC2 Instance OS.

[http://169.254.169.254/latest/user-data](http://169.254.169.254/latest/user-data). It is executed only once on first-time Launch. EC2 doesn't interpret the data, OS needs to understand the user data.

User data is opaque to EC2. It should not be used for password or long term credentials since it is not secure. Limited to 16KB. Can be modified when instance stopped, the contents are only executed once at launch.

cfn-init is a helper script installed on EC2 OS. Used to define desired state in cloud formation templates. It can be used for stack updates for already provisioned stack as compared to user data which only works once on launch. cfn-signal is used to signal CREATE\_COMPLETE to CloudFormation.

EC2 instance roles are roles that an instance can assume and any services running inside the instance gets the role.

Instance Profile allows permissions to get things to get inside the instance. These are delivered via meta-data. These are automatically rotated and always valid. Should always use roles rather than adding access keys into instance. CLI tools will use ROLE credentials automatically.

The SSM Parameter store is a service which is part of Systems Manager which allows the storage and retrieval of parameters - string, stringlist or secure string. The service supports encryption which integrates with KMS, versioning and can be secured using IAM. The service integrates natively with many AWS services - and can be accessed using the CLI/APIs from anywhere with access to the AWS Public Spare Endpoints. Can use forward slashes in parameter name to establish hierarchy.

- **CloudWatch** is for metrics
- **CloudWatchLogs** is for logging

CloudWatch Agent is required to capture OS logs and send to CLoudWatch or CloudWatch Logs.

**EC2 Placement Groups** influence how instances are arranged on hardware.

- **Cluster** - Pack instances close together. All instances in the group use the same rack and sometimes the same host. Can achieve single stream transfer rates of 10Gbps compared to normal 5Gbps. Cannot span AZs. Can span VPC peers but impacts performance. Requires a supported instance type. Use the same type of instance(not mandatory). Launch at same time is recommended. Use case for performance, low latency.
- **Spread** - Keep instances separated. Can span multiple AZs. Located on isolated racks. 7 instances per AZ is the isolated infrastructure limit. Provide infrastructure isolation. Not supported for dedicated instances or hosts.
- **Partition** - Groups of instances spread apart. Divided into partitions, max 7 per AZ. Each partition has its own racks and each partition is isolated. Instances can be launched in a specific partition or auto-placed. Use case for large scale parallel processing systems and topology aware applications(HDFS, HBase, Cassandra). Contain the impact of failure to part of an application.

**Dedicated Hosts**

- Specific Family
- No instance charges
- On-Demand &amp; Reserved Options available
- Host hardware has physical sockets and cores
- Mostly all types of hosts allow running the same type of instance, select during provisioning. Newer types of dedicated hosts allow mix-match.

[https://aws.amazon.com/ec2/dedicated-hosts/pricing/](https://aws.amazon.com/ec2/dedicated-hosts/pricing/)

**Dedicated Hosts Limits/Features:**

- RHEL, SUSE, Windows AMIs are not supported
- Amazon RDS instances are not supported
- Placement groups are not supported.
- Hosts can be shared with other ORG accounts using RAM.
- Generally do it for software with hard license requirements.

Enhanced networking is the AWS implementation of SR-IOV, a standard allowing a physical host network card to present many logical devices which can be directly utilized by instances. This means lower host CPU usage, better throughput, lower and consistent latency. EBS optimization on instances means dedicated bandwidth for storage networking - separate from data networking.

## **Route 53**

Globally resilient DNS service. Hosted zone created with domain registration via R53 or can be created separately. Externally registered domains can point at R53 Public Zone.

Creating a public hosted zone allocates 4 R53 DNS servers. Within VPC, DNS resolver is VPC+2 Address.

R53 Private Hosted zone is associated with VPCs and only accessible within. Can use split-view DNS.

To be able to access private hosted zone, VPC needs to be associated to the private zone.

CNAME cannot be used for naked/apex domain. Alias records can be used in this case. ALIAS records map a NAME to an AWS resource. Can be used both for naked/apex and normal records. There is no charge for ALIAS requests pointing at AWS resources. For AWS services - default to selecting ALIAS.

Route53 health checks can be based on TCP, HTTP/HTTPS, HTTP/HTTPS with string matching. Endpoint checks, CloudWatch Alarm, Checks of Checks(Calculated). If 18% of health checkers report as healthy, the health check is healthy.

- **Simple Routing:** 1 record per name. Each record can have multiple values. All values are returned in a random order. Doesn't support health checks.
- **Failover Routing:** Multiple records of the same name(primary and secondary). If target of health check is unhealthy, any queries return the secondary record for the same name.
- **Multi Value Routing:** Multiple records for the same name and each record can have an associated health check. Up to 8 health records are returned.
- **Weighted Routing:** Weighted routing lets you associate multiple resources with a single domain name and choose how much traffic is routed to each resource. This can be useful for a variety of purposes, including load balancing and testing new versions of software.
- **Latency Routing:** Supports one record with the same name in each AWS region. AWS maintains a database of latency between the users general location and the regions tagged in records. Can also be combined with health checks. Latency database doesn't account **real-time** latency.
- **Geolocation Routing:** Geolocation routing lets you choose the resources that serve your traffic based on the geographic location of your users, meaning the location that DNS queries originate from. Doesn't return closes records, only relevant location records. Checks for State&gt;Country&gt;Continent&gt;default or no answer. Ideal for restricting content based on geography or language re-direction.
- **Geoproximity Routing:** Routing based on distance(and bias) from users. Geoproximity routing lets Amazon Route 53 route traffic to your resources based on the geographic location of your users and your resources. You can also optionally choose to route more traffic or less to a given resource by specifying a value, known as a bias. A bias expands or shrinks the size of the geographic region from which traffic is routed to a resource.

## **Relational Database Service (RDS)**

Relational databases follow a schema and relations between different tables.

**NoSQL Database Types:**

A type of NoSQL database is **Key-Value database**, simply used for storing Key-Value pairs. This type of database is very fast in processing and is a simple collection of data. Commonly used for in-memory caching.

In a **wide column store** each row has one or more keys, one of which is called the partition key. Every item in a table has to have the same key layout. Tables in wide-column stores are just grouping of data, every item in a table can have attributes but they don't have to be the same between items. Every item can have any attribute. No attribute/schema. Only thing that matters in wide column store is that every item has to have the same key layout and unique partition or composite keys. **DynamoDB is an example of wide-column store.**

**Document database** ==&gt; Database can be stored and queries as documents. Best for scenarios such as Orders, Contacts. Ideal for interacting with whole documents or deep attribute interactions. Where each document is unique but it changes over time. Like a Key-Value pair, where key is the id and value is the document data.

Row based databases are where you interact with data based on rows, such as SQL databases. Whole row is read. Ideal when operating on rows. Often called OLTP(Online Transaction Processing).

**Column Database** ==&gt; Data is stored based on columns, that is all data for each column is grouped and stored together. Columns are stored together, ideal for reporting or when all values for a specific attribute are required. Example, Redshift, generally well-suite for reporting and analytics.

![](https://s1ngh.ca/images/image-1612298499171.png)

**Graph Style Database ==&gt;** Relationships between things are formally defined and stored in the database itself along with the data. They are not calculated each and every time a query is run. Nodes have a relationship between them and flow in a direction. Relationship itself may have values. Example, social media stores and data with complex relationships.

**Database Transaction Models:**

**CAP Theorem** - **Consistency**(every read to DB will receive most recent write or it will get an error), **Availability** (every request will receive non-error response without the guarantee of it being the most recent write), **Partition Tolerant**(system can be made of multiple network partitions and continues to operate even if there are number of dropped messages or errors between these network nodes) (resilience) - **Any database model is capable of delivering a maximum of two of these factors.**

- ACID =&gt; Consistency. Atomic, Consistent, Isolated, Durable transactions. Mostly referring to RDS databases. RDS databases limit scalability. 
    - Atomic - All or No components of a transaction succeed or fail.
    - Consistent - Transactions move the database from one **valid** state to another, nothing in-between is allowed.
    - Isolated - If multiple transactions occurs at once, they don't interfere with each other. Each executes as if it's the only one.
    - Durable - Once committed, transactions are durable. Stored on non-volatile memory, resilient to power outages or crashes.
- BASE =&gt; Availability. Basically Available, Soft State, Eventually Consistent. Highly scalable and can deliver high performance. 
    - Basically available - Read and write operations are available as much as possible but whitout any consistency guarantees - kinda, maybe.
    - Soft State - The database doesn't enforce consistency, this is offloaded onto the application/user.
    - Eventually Consistent - If we wait long enough, reads from the system will be consistent.

DynamoDB works in a base like way, offers both eventually and immediately consistent reads(but application needs to be aware). It also offers ACID functionality such as DynamoDB transactions. BASE is mostly NoSQL style database, ACID is mostly RDS database. NoSQL/DynamoDB mentioned with ACID it is usually referring to DynamoDB transaction.

Require justification why a database needs to be run on EC2 instance instead of running it through AWS service.

Why database should be put on EC2:

- - DB or DB Version AWS don't provide
    - Advanced DB Option tuning(DBROOT), however AWS now provides flexibility with DB tuning
    - Specific OS/DB combination
    - Architecture AWS don't provide (replication/resilience)
    - Access to DB instance OS
    - Decision makers who '**just want it**'

Why database should **not** be put on EC2:

- Admin overhead
- Backup / DR Management
- EC2 is single AZ
- Features - some AWS DB products are amazing
- EC2 is ON or OFF - no serverless, no easy scaling.
- Replication - skills, setup time, monitoring &amp; effectiveness
- Performance - AWS managed database is optimized and feature-rich

Relational Database Service(RDS) is a **DatabaseServer-as-a-service**. Provides managed database instance (1+ Databases). Supports MySQL, MariaDB, PostgreSQL, Oracle, Microsoft SQL Server and **Amazon Aurora**.

An RDS instance can contain multiple user-created databases. The only method to connect to RDS is through a CNAME. RDS instance types =&gt; db.m5, db.r5 and db.t3. All instance types have various configurations of CPUs.

A single AZ RDS instance has a single block storage connected. Storage can be io1, gp2 and magnetic, similar to EC2. Billed for RDS instance, amount of storage, GB/m. Extra for io1 storage.

Access to RDS instance is controlled via a security group that's attached to the RDS instance.

**Provisioning RDS instance:**

1. Create Subnet Group 
    - Select the subnet groups that the database will go in
2. Create database 
    - Select database engine. Pay license or bring your own license for commercial database engines.
    - Select vpc and subnet group association.
    - Configure security group

MultiAZ is a feature of RDS which provisions a standby replica which is kept in sync Synchronously with the primary instance. The standby replica cannot be used for any performance scaling ... only availability. Backups, software updates and restarts can take advantage of MultiAZ to reduce user disruption.

In a MultiAZ setup, the CNAME normally points to the primary instance for RDS. The standby RDS instance cannot be accessed under normal operations, it is just there getting **synchronous replication**. When a change is being written to the primary RDS' storage, the replication to standby is also carried out at the same time where it writes the data to the secondary instance's storage. When a failure occurs on the primary instance, the CNAME points to the standby RDS instance withing 60-120 seconds. This doesn't provide fault tolerance, only **high-availability.**

- Multi-AZ is extra cost for standby replica, is not covered in free-tier
- Standby can't be directly used, therefore no performance improvements
- 60-120 seconds failover
- Same region only (other AZs in the VPC)
- Backups taken from Stanby (removes performance impact on the primary instance)
- Failover reasons: AZ Outage, Primary Failure, Manual failover, instance type change and software patching.

**RTO vs RPO**

Recovery Point Objective - Maximum amount of data loss. Time between last backup and the incident. Lower values Cost more.

Recovery Time Objective - Time between the DR event and full recovery. Influenced by process, staff, tech and documentation.

RDS Backups:

RDS backups are performed to AWS managed S3 buckets. Therefore, this makes the backups region resilient, since the buckets are replicated to multiple AZs in the same region.

In a Multi-AZ RDS environment, the backups are always performed the standby instance.

- Manual Snapshots: Stored inside S3, function like EBS snapshots. First snapshot is a full copy of the volume, and then onward all snapshots are incremental. There is a brief interruption to the flow of data between the computer resource and the storage. They don't expire, so have to be cleared manually. On deleting an RDS instance, the manual snapshots are not automatically removed. Snapshot is taken of the whole instance, so all databases in an instance.
- Automatic Backups: Snapshots that occur automatically at a specific window. These are automatically cleaned up, Retention 0 to 35 days. When deleting an instance, the automatic backups can be retained, however they will still expire based upon their retention configuration.

Every 5 minutes, database transaction logs are written to S3, these logs contain changes in data of the database.

**RDS Restores**

- Creates a NEW RDS instance - new endpoint Address
- Snapshots = single point in time, creation time
- Automated = any 5 minute point in time
- Backup is restored and transaction logs are replayed to bring DB to desired point in time
- Restores aren't fast - **RTO!!**

Read-Replicas are read-only DB replicas, they have their own database endpoint address, and they are kept in sync using **asynchronous replication,** data is first written fully to the primary instance, and once it has been written, it is replicated to the secondary instance. They can be in the same region, or cross-region replicas.

RDS Read Replicas can be added to an RDS Instance - 5 direct read-replicas per primary instance.

They provide read performance scaling for the instance, but also offer low RTO recovery for any instance failure issues. N.B they don't help with data corruption as the corruption will be replicated to the RR.

Read-replicas can have read-replicas but lag starts to be a problem. Provide global performance improvements.

- Snapshots &amp; backups Improve RPO
- Read-Replica's offer near-zero RPO. RR can be promoted to a primary R/W instance quickly.
- Rad only until promoted, irreversible
- Global availability improvements, global resilience.

<p class="callout danger">Any form of replication can replicate data corruption.</p>

**Amazon RDS Security**

- SSL/TLS (in transit) is available for RDS, can be mandatory
- RDS support EBS volume encryption - KMS
- Handled by HOST/EBS
- AWS or Customer Managed CMK generates data keys
- Data keys used for encryption operations
- Storage, Logs Snapshots &amp; replicas are encrypted
- Encryption can't be removed once added
- RDS MSSQL and RDS Oracle support TDE(Transparent Data Encryption) - Encryption handled within the DB engine.
- RDS Oracle supports integration with CloudHSM -Much stronger key control(even from AWS)

![](https://s1ngh.ca/images/image-1612326817825.png)

Normally, logins to RDS are controlled using local database users. To use IAM authentication with RDS:

![](https://s1ngh.ca/images/image-1612327044147.png)

**Aurora**

Aurora architecture uses a cluster. A single primary instance + 0 or more replicas. Replicas inside Aurora can provide benefits of both MultiAZ and read-replicas.

Aurora has no local storage and uses cluster volume providing faster provisioning, improved availability and better performance. Replication occurs at the storage level so no performance impacts on the database instance.

Cluster shared storage is All SSD based, with high IOPS and low latency. Storage is billed based on what's used. High water mark - billed for the most used. Storage which is freed up can be re-used. Replicas can be added or removed without requiring storage provisioning.

Aurora clusters have multiple endpoints. Cluster endpoint always points to the primary instance. The reader endpoint will load balance across all the available replicas.

- Backups in Aurora work in the same way as RDS
- Restores create a new cluster
- Backtrack can be used which in-place rewinds to a previous point in time. Needs to be enabled on a per-cluster basis.
- Fast clones make a new database MUCH faster than copying all the data - copy-on-write.

**Aurora Serverless**

Scalable in ACU(Aurora Capacity Units), has a minimum and maximum ACU. Cluster adjusts based on load, Same resilience as Aurora(6 copies across AZs). ACUs are stateless. They are provisioned from a shared pool managed by AWS. Connections to the Aurora serverless cluster go through a **Proxy Fleet.** Due to the intermediate proxy fleet, scaling is smooth and flexible.

Use Cases:

- Infrequently used applications.
- New applications
- Variable workloads
- Unpredictable workloads
- Development and test databases
- Multi-tenant applications

Aurora serverless cluster can scale down to 0 ACU and pause - meaning the cluster costs will be for storage only.

**Aurora Global Database** allow data to be replicated globally providing significant RPO and RTO improvements for BC and DR planning. Additionally global databases can provide performance improvements for customers .. with data being located closer to them, in a read-only form.

- Cross-region DR and BC
- Global read scaling - low latency performance improvements.
- ~1s or less replication between regions.
- No impact on DB performance.
- Secondary regions can have 16 replicas.(can be promoted to R/W)
- Max. of 5 secondary regions currently.

**Aurora Multi-Master Writes** allows multiple instances to perform reads and writes at the same time - rather than only one primary instance having write capability in a single-master cluster. There's no load-balance concept, application can initiate connection to any or all nodes. In-memory caches are also replicated.

In single-master mode, failover takes time as the write role needs to switch from one instance to another. In multi-master cluster, application can be fault-tolerant by maintaining connection to multiple writers. Application needs to be able to manually load-balance.

**Database Migration Service** is a managed database migration service. Runs using a replication instance in EC2. Source and destination endpoints pointing to source and destination target databases. One endpoint must be on AWS.

- **Full load migration (one off)**
- **Full Load + CDC(change data capture)**
- **CDC only (eg, initial backup is taken using native tooling then CDC continues ongoing replication).**

**Schema Conversion Tool** is used when converting from one database engine to another. Works with OLTP and OLAP databases.

DMS can utilize snowball:

1. Use SCT to extract data locally and move to snowball device.
2. Ship device to AWS and data is loaded onto S3 bucket.
3. DMS migrates from S3 into target store.
4. CDC can capture changes and via S3 intermediary they are also written to the target database.

## **Elastic File System(EFS)**

The Elastic File System (EFS) is an AWS managed implementation of NFSv4 which allows for the creation of shared 'filesystems' which can be mounted within multi EC2 instances.

EFS can be accessed from on-premises, VPN, DX. EFS exists in a VPC. EFS mount targets are put into AZs in a VPC.

- Officially supported for Linux only
- General Purpose and Max I/O performance modes
- Bursting and Provisioned Throughput modes.
- Standard and Infrequent Access(IA) Storage classes are available.
- Lifecycle policies can be used with classes.

## **HA &amp; Scaling**

**Regional and Global AWS Architecture**

- Global Service Location &amp; Discovery
- Content Delivery (CDN) and optimization
- Global health checks &amp; Failover
- Regional entry point
- Scaling &amp; Resilience
- Application services and components

CDN's are used to cache content globally as close to end users as possible to improve performance. Globally DNS is used for service discovery and regional based health checks and request routing.

![](https://s1ngh.ca/images/Y8FFtkVjiKjrd9Ug-image-1639764689728.png)

**ELB Evolution**

- 3 types of load balancers within AWS.
- Split between v1 and v2. Avoid v1.
- CLB(Classic Load Balancer) - v1. Not many layer 7 functions, lacking features, 1 SSL per CLB.
- **Application Load Balancer (ALB)** - v2 - HTTP/S/WebSocket
- **Network Load Balancer (NLB)** - v2 - TCP, TLS &amp; UDP

**ELB Architecture**

![](https://s1ngh.ca/images/fPdmMsQMkTbcu2zM-image-1639765524104.png)

![](https://s1ngh.ca/images/oSF4SaVWHbxX9y92-image-1639765700186.png)

![](https://s1ngh.ca/images/VlWqFvpAHfsOP7yE-image-1639765941078.png)

- ELB is a DNS A record pointing at 1+ Nodes per AZ.
- Nodes(in one subnet per AZ) can scale
- Internet-facing means nodes have public IPv4 IPs
- Internal is private only IPs
- EC2 doesn't need to be public to work with a LB.
- Listener configuration controls what the LB does.
- 8+ Free IPs per subnet, and /27 subnet to allow scaling.

**ALB**

- Layer 7 load balancer. Listens on HTTP and/or HTTPS
- No other Layer 7 protocols and no TCP/UDP/TLS listeners
- L7 content type, cookies, custom headers, user location and app behavior.
- HTTP HTTPS(SSL/TLS) always terminated on the ALB - no unbroken SSL. A new connection is made to the application.
- ALBs must have SSL certificates is HTTP is used.
- ALBs are slower than NLB due to more levels of the network stack to process.
- Health checks evaluate layer 7 application health.
- Rule direct connections which arrive at a listener. Processed in priority header. Rule conditions can be host-header, http-header, query strings, etc. Rule Actions can be forward, redirect, fixed-response, authenticate-oidc &amp; authenticate-cognito.

**NLB**

- Layer 4 load balancer. TCP, TLS, UDP, TCP\_UDP.
- No visibility or understanding of HTTP or HTTPS
- No headers, no cookies, no session stickiness.
- Superrrrrrrrr Fast.
- ...SMTP, SSH, Game Server, financial apps (not http/s)
- Health check just check ICMP/TCP handshake.
- NLB's can have static IP's - useful for whitelisting.
- Forward TCP to instances, unbroken encryption.
- Used with private link to provide service to other VPCs.

**ALB vs NLB**

- Unbroken Encryption - NLB
- Static IP for whitelisting - NLB
- Fastest performance - NLB
- Protocols not HTTP or HTTPS - NLB
- Privatelink - NLB
- Other use cases - ALB

**Launch Configurations** and **Launch Templates** allow defining configuration of an EC2 instance in advance. AMI, Instance Type, Storage &amp; Key pair. Networking and security groups. User data &amp; IAM role. **Both are not editable.** Launch Templates has versions. LT provide newer features - including T2/T3 unlimited, placement groups, capacity reservations, elastic graphics.

Launch Configuration are used as part of Auto scaling groups. Launch Template can also be used in Auto scaling groups as well as for provisioning EC2 instances from UI/CLI.

An *Auto Scaling group* contains a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. An Auto Scaling group also enables you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service. ASG has a minimum, desired and maximum specification. Keep running instances at the desired capacity by provisioning or terminating instances. Scaling policies automate based on metrics.

When instances are provisioned in multiple subnets, there's an attempt to keep the number of instances even in all selected subnets.

**Scaling Policies**

ASGs don't need scaling policies, they can have none.

- **Manual Scaling** - Manually adjust the desired capacity
- **Scheduled Scaling -** Time based adjustment
- **Dynamic Scaling**  
    
    - **Simple** - Rules based on metric alarm, eg, CPU.
    - **Stepped Scaling** - Bigger +/- based on difference. Step adjustments based on alarm rate.
    - **Target Tracking** - Based on metric target. CPU utilization, AverageNetworkIn, AverageNetworkOut, etc.. Example to keep aggregate CPU ~40%.
    - SQS - ApproximateNumberOfMessagesVisible
- **Cooldown Periods** - Wait at the end of scaling action before performing another action.

ASG are self-healing as the monitor health of instances using EC2 instance checks. To maintain HA with single instance, can use trick with ASG to have a Launch Template for ASG and set min, desired, max to 1, instance can be re-provisioned in another AZ if it fails.

**Scaling Processes**

- Launch and Terminate - SUSPED and RESUME
- AddToLoadBalancer - add to LB on launch
- AlarmNotification - accept notification from CW
- AZRebalance - Balances instances evenly across all of the AZs
- HealthCheck - instance health check on/off
- ReplaceUnhealthy - Terminate unhealthy and replace
- ScheduledActions - Scheduled on/off
- Standby - use this for instances 'InService vs Standby'

Autoscaling groups are free. Only created resources are billed. Use cool downs to avoid rapid scaling. Think about more, smaller instances - granularity. Use with ALB's for elasticity - abstraction. ASG defines WHEN and WHERE, LT defines WHAT.

**ASG Lifecycle Hooks** perform custom actions by pausing instances as an Auto Scaling group launches or terminates them. When an instance is paused, it remains in a wait state either until you complete the lifecycle action using the complete-lifecycle-action command or the CompleteLifecycleAction operation, or until the timeout period ends (one hour by default).

![](https://s1ngh.ca/images/C4DRa2bs4x7u4mkL-image-1639770362442.png)

Amazon EC2 Auto Scaling can determine the health status of an instance using one or more of the following:

- Status checks provided by Amazon EC2 to identify hardware and software issues that may impair an instance. The default health checks for an Auto Scaling group are EC2 status checks only.
- Health checks provided by Elastic Load Balancing (ELB). These health checks are disabled by default but can be enabled. Application aware health checks.
- Custom health checks.

Health check grace period is the delay before starting check. Default 300s. Accounts for time of system launch, bootstrapping and application start.

![](https://s1ngh.ca/images/iy7h6g66hz2yhyu9-image-1639770889977.png)

![](https://s1ngh.ca/images/YC5D1hDRyhg4UZIZ-image-1639771045221.png)

Where possible, instances should be made stateless and the states should be stored externally on a service such as DynamoDB.

**Gateway Load Balancers** enable you to deploy, scale, and manage virtual appliances, such as firewalls, intrusion detection and prevention systems, and deep packet inspection systems. It combines a transparent network gateway (that is, a single entry and exit point for all traffic) and distributes traffic while scaling your virtual appliances with the demand.

- Traffic enters/leaves via GWLB endpoints
- The GWLB balances across multiple backend applications
- Traffic and metadata is tunneled using GENEVE protocol.

![](https://s1ngh.ca/images/YyH2yJY3E1q6wTBg-image-1639783758444.png)

## **Serverless and Application Services**

In a tiered architecture each tier is dependent and has to be running in order to ensure functionality.

Queue architecture de-couples tiers and allows improved asynchronous communications and scaling.

Event driven architecture are a combination of Event Producers, Event Consumers and Event Router.

With event driven architecture:

- No constant running or waiting for things
- Producers generate events when something happens
- ..clicks, error , criteria met, uploads, actions
- Events are delivered to consumers
- ..actions are taken &amp; the system returns to waiting
- Mature event-driver architecture only consumes resources while handling events(serverless...)

**AWS Lambda**

- Function-as-a-Service (FaaS) - short running &amp; focussed
- Lambda function - a piece of code lambda runs
- Functions use a runtime
- Functions are loaded and run in a runtime environment
- The environment has a direct memory (indirect CPU) allocation
- Billed for the duration that a function runs
- Key part of serverless architecture.

![](https://s1ngh.ca/images/mGdQ5gQeTTvhVV6h-image-1639887418944.png)

**Use Cases for Lambda:**

- Serverless Applications (S3, API Gateway, Lambda)
- File Processing (S3, S3 Events, Lambda)
- Database Triggers (DynamoDB, Streams, Lambda)
- Serverless CRON ( EventBridge/CWEvents + Lambda)
- Realtime Stream Data Processing (Kinesis + Lambda)

Lambda running by default using public networking has network connectivity to public space AWS services and public internet. Offers the best performance because no customer specific VPC networking is required. Lambda functions have no access to VPC based services unless public IPs are provided &amp; security controls allow access.

Lambda functions running in a VPC obey all VPN networking rules and require VPC networking to access other services and internet. Lambda services requires EC2 network permissions to create network interfaces. A single connection from Lambda service VPN to private VPC is created for every unique set of subnet and security groups. Network interfaces are created once on function creation/modification, leading to no invocation delay.

Lambda execution roles are IAM roles attached to lambda functions which controller the PERMISSIONS the Lambda function receives. Lambda resource policy controls WHAT services and accounts can invoke lambda functions(like bucket policy).

- Logs from Lambda Executions - CloudWatchLogs. By default into a Log group by the name of the function
- Metrices(Invocation Success/Failure, retires, latency) - CloudWatch
- Can be integrated with X-Ray for distributed tracing
- CloudWatch Logs requires permissions via execution role.

**Lambda Invocation**

- **Synchronous Invocation:** CLI/API invoke a lambda function, passing in data and wait for a response, then lambda function responds with data or fails. Example, connection from Client through API gateway to Lambda function.
- **Asynchronous Invocation:** Typically used when AWS services invoke lambda functions. Event is sent without waiting for any response/action. If processing of event fails, lambda will retry between 0 and 2 times. Lambda handles the retry logic. The lambda function needs to be idempotent --&gt; reprocessing a result should have the same end state. Events can be sent to dead letter queues after repeated failed processing.
- **Event Source mappings**:: Typically used on stream or queues which don't support event generation to invoke lambda. Event source mappings read/poll from the stream or queue and deliver event batches to lambda. Event batches are processed OK or FAIL as a batch. Permissions from the lambda execution roles are used by the event source mapping to interact with the event source. SQS queues or SNS topics can be used for any discarded failed event batches.

A lambda version is immutable. $Latest points at the latest version. Aliases point at a version.

 A lambda function performs a cold start when it's first invocated, this includes creation and configuration of the function. The same execution context can be reused for a warm start if this carried out shortly after the cold start before the context is removed. Lambda function can reuse an execution context but it should be always be designed assuming that **IT CAN'T**. Things created outside the lambda function handler and kept from future invocations of the execution context. Concurrent executions require multiple contexts, can use provisioned concurrency so AWS will create and keep warm context ready to be used.

EventBridge is replacing CloudWatch Events.

CloudWatch Events and EventBridge have visibility over events generated by supported AWS services within an account.

They can monitor the default account event bus - and pattern match events flowing through and deliver these events to multiple targets.

They are also the source of scheduled events which can perform certain actions at certain times of day, days of the week, or multiple combinations of both - using the Unix CRON time expression format.

**Serverless**

- Few/No Servers
- Applications are collection of small and specialized functions
- Stateless and Ephermeral environments
- Event-Driven
- FaaS is used where possible for compute functionality
- Managed Services are used where possible

**Simple Notification Service (SNS)** is a PUB SUB style notification system which is used within AWS products and services but can also form an essential part of serverless, event-driven and traditional application architectures. It coordinates the sending and delivery of messages. Messages are &lt;=256KB payloads.

SNS Topics are the base entity of SNS - permissions and configurations. Publishers send messages to TOPICS. Subscribers receive messages SENT to TOPICS.

SNS supports a wide variety of subscriber types including other AWS services such as LAMBDA and SQS.

- SNS supports delivery status and delivery retries.
- HA and Scalable(region)
- Supports Servicer Side Encryption
- Cross-Account allow via TOPIC policy.

**Step Functions** allow creating state machines. State machines are serverless workflows.. start--&gt;states--&gt;end. States are things which occur. Maximum duaring of standard workflow state machine is 1 year. For express workflow state machine, max. duration is 5 mins. These can be started via API Gateway, IOT Rules, EventBridge, Lambda, etc. Created in Amazon States Language(ASL). IAM Role is used for permissions.

States:

- SUCCEED &amp; FAIL
- WAIT
- CHOICE
- PARALLEL
- MAP
- TASK - single unit of work performed by state machine. This sate performs the actual work by coordinating with other services.

**API Gateway** is a managed service from AWS which allows the creation of API Endpoints, Resources &amp; Methods. The API gateway integrates with other AWS services - and can even access some without the need for dedicated compute. It serves as a core component of many serverless architectures using Lambda as event-driven and on-demand backing for methods. It can also connect to legacy monolithic applications and act as a stable API endpoint during an evolution from a monolith to microservices and potentially through to serverless.

![](https://s1ngh.ca/images/4RBwDJrcheOs1Skm-image-1640061721758.png)

**API Gateway Endpoint Types:**

- Edge-optimized
- Routed to the nearest CloudFront POP
- Regional - Clients in the same region
- Private - Endpoint accessible only within a VPC via interface endpoint.

**API**s are deployed to stages, each stage has one deployment. Stages can be enabled for canary deployments. If done, deployed are made to the canary not the stage. Stages enabled for the canary deployments can be configured so a certain percentage of traffic is send to the canary. This can be adjusted over time - or the canary can be promoted to make it the new base stage.

**API Gateway Errors:**

- 4xx - Client Error - Invalid Request on client side
- 5xx - Server Error - Valid request, backend issue.
- 400 - Bad Request
- 403 - Access Denied
- 429 - API Gateway can throttle - this means a configured amount has been exceeded
- 502 - Bad Gateway Exception
- 503 - Service Unavailable
- 504 - Integration Failure/Timeout - 29s limit.

API Gateway cache TTL default is 300 seconds. Configurable min 0 and max 3600s. Can be encrypted. Cache size 500MB to 237GB. Calls are only made to backend integrations is a cache miss. Cache is defined per stage within API gateway.

**Simple Queue Service(SQS)** is a public, pully managed, highly available queue service - Standard or FIFO. Messages up to 256KB in size, if large data needs to be used it can be linked. Clients can send or poll queue. Client received messages are hidden for visibility timeout, then either reappear(retry) or are explicitly deleted. Dead-Letter queues can be used for problem messages.

ASGs can scale and Lambdas invoke based on queue length.

Standard queues guarantee at least once delivery but no order. FIFO guarantee exactly once delivery and in order.

FIFO performance - 3000 messages per second with batching, or up to 300 messages per second without. SQS 1 request = 1-10 messages up to 256KB total. Short (immediate) and Long(waitTimeSecond) polling. Long polling uses fewer requests as it sits waiting for messages on the queue if none exist. SQS supports encryption at rest using KMS. By default data is encrypted in-transit from SQS. Identity policy/Queue policy can be used to control access from the same account and queue policy can also allow access from external accounts.

**Kinesis data streams** are a streaming service within AWS designed to ingest large quantities of data and allow access to that data for consumers. Public service and highly available by design. Streams store a 24-hour moving window of data. Multiple consumers access data from the moving data. Kinesis is ideal for dashboards and large scale real time analytics needs. Kinesis data firehose allows the long term persistent storage of kinesis data onto services like S3. Stream uses a shard architecture. Each shard allows for 1MB/s ingestion and 2MB/s consumption. Kinesis data records are stored across shards.

SQS vs Kinesis - SQS usually 1 production group, 1 consumption group. SQS designed for **decoupling** and **asynchronous** communications. No persistence of messages, no window. Kinesis designed for huge scale ingestion/streaming, multiple consumers, rolling window. Kinesis designed for data ingestion, analytics, monitoring, app clicks.

**Kinesis Data Firehose** is a fully managed service to load data for data lakes, data stores and analytics services. Automatic scaling, fully serverless, resilient. Near real time delivery (~60 seconds). Supports transformation of data on the fly. Billing based on volume through firehouse.

**KINESIS DATA STREAM ARE REAL-TIME, KINESIS DATA FIREHOSE ARE <span style="text-decoration: underline;">NEAR</span> REAL-TIME.**

![](https://s1ngh.ca/images/Zyfqk03P2hEIXRnB-image-1640233891537.png)

**Kinesis Data** **Analytics** provides real time processing of data using SQL. Ingests from Kinesis data streams or firehose. Support destinations are Firehose(indirectly Firehose destinations), Lambda, Kinesis Data Streams.

![](https://s1ngh.ca/images/xnXQoH5cv15SMPFZ-image-1640234248188.png)

Use Case Kinesis:

- Streaming data needing real-time SQL processing
- Time-series analytics
- Real-time dashboards
- Real-time metrics

**Amazon Cognito** provides Authentication, Authorization and user management for web/mobile apps.

A user pool is a user directory in Amazon Cognito. With a user pool, your users can sign in to your web or mobile app through Amazon Cognito. Your users can also sign in through social identity providers like Google, Facebook, Amazon, or Apple, and through SAML identity providers. Whether your users sign in directly or through a third party, all members of the user pool have a directory profile that you can access through a Software Development Kit (SDK). Users get a JSON Web Token (JWT). **These cannot be used to access AWS resources.**

Amazon Cognito identity pools (federated identities) enable you to create unique identities for your users and federate them with identity providers. With an identity pool, you can obtain temporary, limited-privilege AWS credentials to access other AWS services.

![](https://s1ngh.ca/images/tjbI8uOMYwhDEduw-image-1640234901305.png)

![](https://s1ngh.ca/images/mPDqx1eZvDLwuP0M-image-1640235018194.png)

![](https://s1ngh.ca/images/wtU9W5YZkcyAkZls-image-1640235131536.png)

User Pools allow sign-in/sign-up. Identity Pool swap credentials for temporary AWS credentials.

## **Global Content Delivery and Optimization**

**CloudFront** is a Content Delivery Network(CDN).

- **Origin** - Source location of content. S3 Origin or Custom Origin.
- **Distribution** - The configuration unit of CloudFront.
- **Edge Location** - Local cache of data.
- **Regional Edge Cache** - Larger version of an edge location. Provides another layer of caching.

A behavior is a configuration within a distribution.

![](https://s1ngh.ca/images/qIFCIkzn9zwHpinF-image-1640236439916.png)

A distribution can have multiple behaviors, Default is (\*) behavior. Restrict Viewer Access can be done on a per-behavior basis and Trusted Signers can be set.

 Cache TTL can be used to specify how often the cache is validated against the origin. If the origin is un-modified, it returns 304 NOT MODIFIED and the edge serves the cached version. If it is modified, origin returns with 200 OK with the modified version.

An object is not expired as long as it's within it's TTL.

- Default TTL(behavior) -&gt; 24 hours (validity period).
- Minimum TTL and Maximum TTL act as limiters for any per-object timers like below.
- Origin header can direct CloudFrount to set expiration timers. 
    - Cache-Control max-age (seconds).
    - Cache-Control s-maxage (secons)
    - Expires

Cache invalidations are performed on a distribution based on pattern matching, applies to all edge locations and therefore takes time.

Can use versioned files names to help with cost as compared to cache invalidation.

**AWS certificate Manager(ACM)** is a service which allows the creation, management and renewal of certificates. It allows deployment of certificates onto **supported** AWS services such as CloudFront and ALB.

Each CloudFront distribution recieves a default domain name and gets the default cloudfront wildcard certificate. Alternate domain names can be used, Ownership is verified using a matching certificate(regardless of HTTPS being used). ACM is a regional service. So certificate needs to be created in the same region as the service. <span style="text-decoration: underline;">**For global services(CloudFront), certificate needs to be created in us-east-1.**</span>

For CloudFront SSL connections, certificate needs to be a valid public certificate. Self-Signed certificates do not work with CloudFront.

With CloudFront can either use SNI method or dedicated IP(for old browsers, extra charges).

The certificate on CloudFront needs to match the domain name used by the client. The certificate on origins needs to match the domain name used by CloudFront to contact those origins.

Origin Types:

- S3 - Can also be created as a custom origin with static hosting enabled.
- AWS media package channel endpoints
- AWS media store container endpoints
- Everything else (web servers) - Custom Origin

For S3 endpoints, the viewer and origin protocols are matched. Custom origin allows specifying HTTP/HTTPS ports, protocol policy for origin, minimum SSL version.

**Origin Access Identities** are a feature where virtual identities can be created, associated with a CloudFront Distribution and deployed to edge locations.

Access to an s3 bucket can be controlled by using these OAI's - allowing access from an OAI, and using an implicit DENY for everything else. They are generally used to ensure no direct access to S3 objects is allowed when using private CF Distributions.

- Origin Access identities (OAI) - for S3 Origins
- Custom Headers - For Custom Origins
- IP Based FW Blocks - For Custom Origins.

**Lambda@Edge** allows cloudfront to run lambda function at CloudFront edge locations to modify traffic between the viewer and edge location and edge locations and origins. Currently supports node.js and python runtimes. Run in the AWS public space, layers are not supported.

![](https://s1ngh.ca/images/T1vBxv7S5XojTK6j-image-1640274073030.png)

Use Cases:

- A/B testing - Viewer Request
- Migration between S3 Origins - Origin Request
- Different objects based on device - Origin Request
- Content By Country - Origin Request

[https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-examples.html#lambda-examples-redirecting-examples](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-examples.html#lambda-examples-redirecting-examples)

**AWS Global Accelerator** is designed to improve global network performance by offering entry point onto the global AWS transit network as close to customers as possible using Anycast IP addresses.

- Moves the AWS network closer to customers
- Connections enter at edge using anycast IPs
- Transit over AWS backbone to 1+ locations.
- **Can be used for NON HTTP/S (TCP/UDP) - Whereas CloudFront is for HTTP/S caching.**

## **Advanced VPC Networking**

VPC FLow logs is a feature allowing the monitoring of traffic flow to and from interfaces within a VPC. VPC Flow logs can be added at a VPC, Subnet or Interface level. Flow Logs DON'T monitor packet contents **only metadata. NOT real-time.** Flow Logs can be stored on S3 or CloudWatch Logs. Can use Athena for querying S3.

![](https://s1ngh.ca/images/xf0mcxYfRUW15pe0-image-1640275133306.png)

![](https://s1ngh.ca/images/GYVOJ7sbjr4dmXtJ-image-1640275307500.png)

**Egress-Only internet gateways** allow outbound (and response) only access to the public AWS services and Public Internet for **IPv6** enabled instances or other VPC based services.

**VPC Gateway endpoints** are a type of VPC endpoint which allow access to S3 and DynamoDB without using public addressing.

Gateway endpoints add 'prefix lists' to route table, allowing the VPC router to direct traffic flow to the public services via the gateway endpoint. Highly available (HA) across all AZs in a region by default. Endpoint policy is used to control what it can access. Regional, can't access cross-region services. Can help prevent leaky buckets by setting bucket to private only and allowing access only from a gateway endpoint.

**VPC Interface endpoints** are used to allow private IP addressing to access public AWS services. S3 and DynamoDB are handled by gateway endpoints - other supported services are handled by interface endpoints. Interface Endpoints now also support S3. Unlike gateway endpoints - interface endpoints are not highly available by default - they are normal VPC network interfaces and should be placed 1 per AZ to ensure full HA. Network access controlled via Security Groups, endpoint policies restrict what can be done with the endpoint. Only support TCP and **IPv4.** Uses **PrivateLink** technology. Endpoint provides a NEW service endpoint DNS. Endpoint gets a regional and zonal DNS. PrivateDNS overrides the default DNS for services.

**VPC peering** is a software defined and logical networking connection between **two** VPC's. They can be created between VPCs in the same or different accounts and the same or different regions. VPC peering does NOT support transitive peering. Optionally public hostnames can resolve to private IPs. Same region security groups can reference peer SGs.

## **Hybrid Environments and Migration**

**AWS Site-to-Site VPN** is a hardware VPN solution which creates a highly available IPSEC VPN between an AWS VPN and external network such as on-premises traditional networks. VPNs are quick to setup vs direct connect, don't offer the same high performance, but do encrypt data in transit.

VPN connection between VGW(Virtual Private Gateway) and CGW(Customer Gateway). Virtual Private Gateway is a local object on AWS and can be used as target for routes. VGW has physical endpoints in different AZs, making it highly available by design. Two VPN tunnels are created between each endpoint and remote endpoint.

Route propagation means routes are added to RTs automatically.

VPN Speed Limitations -&gt; 1.25Gbps. Hourly cost, GB out cost. Can be used as a backup for/with DX.

**Direct Connect** is AWS's physical private link connecting business premises to its public and private services. 1Gbps or 10Gbps network port into AWS. Port is allocated to customer at a DX location(1000-Base-LX or 10GBASE-LR). Cable from AWS DX to Customer router(requires VLANS/BGP). When applying for DX, customer is allocated a port, customer has to arrange for how to get connection from that port to premises.

Multiple Virtual Interfaces (VIFS) over one DX. Each VIF is a VLAN and BGP connection from customer to DX router. Private VIF (VFPC) &amp; Public VIF (Public Zone Services). Each private VIF connects to one VPC.

- DX takes much longer to provision vs VPN.
- DX port provisioning is quick, the cross-connect takes longer, extension to premises can take weeks/months.
- Use VPN first, then replace with DX(or leave as backup).
- Faster -&gt; 40Gbps with Aggregation
- Low consistent latency, doesn't use business bandwidth.
- No native encryption in DX. Can create IPSec VPN over DX.

![](https://s1ngh.ca/images/OHmuApxhQ08Yw0Oj-image-1640311253898.png)

![](https://s1ngh.ca/images/YSk5JX1sv0x6hsEa-image-1640311372397.png)

![](https://s1ngh.ca/images/2hvXVQvZGTJ6VEzZ-image-1640311575654.png)

![](https://s1ngh.ca/images/QEP91feIq88QOixU-image-1640311756838.png)

**The AWS Transit gateway** is a network gateway which can be used to significantly simplify networking between VPC's, VPN and Direct Connect. It can be used to peer VPCs in the same account, different account, same or different region and supports transitive routing between networks. Significantly reduces network complexity. Single network object - HA and Scalable. Attachments to other network types - VPC, Site to Site VPN, DX.

- Transit Gateway supports transitive routing.
- Can be used to create global networks. Can peer multiple transit gateways.
- Share between accounts using RAM.
- Peer with different regions, same or cross account.

**Storage Gateway** is a hybrid storage virtual appliance. Can be run on-premise or in datacenter in VMWare.

Use Cases:

- Allows extension of file &amp; volume storage into AWS.
- Allows volume storage hosted locally and perform asynchronous backup into AWS.
- Can perform tape backup into AWS. Migration of existing infrastructure into AWS.

**Storage Gateway Modes:**

- Tape Gateway (VTLS) Mode - Virtual tapes =&gt; S3 and Glacier
- File Mode - SMB and NFS - File Storage backed by S3 Objects
- Volume Mode (Gateway Cache/Stored) - iSCSI. Block storage backed by S3 and EBS Snapshots. Stored mode for asynchronous backups, cached mode for migrating to AWS.

**Snowball, Snowball Edge** and **Snowmobile** are three parts of the same product family designed to allow the physical transfer of data between business locations and AWS. Used to move large amounts of data IN and OUT of AWS. Ordered from AWS Empty, Load up, Return or order from AWS with data, empty, Return.

Snowball - Ordered from AWS, log a job, Device delivered (not instant). Data encryption uses KMS. 50TB or 80TB Capacity. 1Gbps or 10Gbps connectivity. 10TB to 10PB economical range (multiple devices). Multiple devices can be ordered to multiple premises. Only storage.

Snowball Edge - Both Storage and Compute. Larger capacity vs Snowball. 10Gbps, 10/25(SFP), 45/50/100 Gbps connectivity.

- Storage Optimized (with EC2) - 80TB, 24vCPU, 32Gib RAM + 1 TB SSD.
- Compute Optimized - 100TB + 7.68 NVME, 52 vCPU and 208 GiB RAM.
- Compute with GPU - Computer Optimized + GPU.

Snowball Edge ideal for remote sites or where data processing on ingestion is needed.

Snowmobile - Portable DC within a shipping container on a truck. Special order. Ideal for single location when 10 PB+ is required. Up to 100PB per snowmobile. Not economical for multi-site or sub 10PB.

**Directory service** is a product which provides managed directory service instances within AWS. Runs within a VPN. It is deployed into multiple AZs to implement HA. Some AWS services NEED a directory e.g. Amazon Workspaces.

It functions in three modes

- Simple AD - An implementation of Samba 4 (compatibility with basics AD functions). For simple requirements.
- AWS Managed Microsoft AD - An actual Microsoft AD DS Implementation. For applications in AWS which need MS AD DS, or need to trust AD DS.
- AD Connector which proxies requests back to an on-premises directory. For AWS services which need a directory without storing any directory info in the cloud.

**AWS DataSync** is a product which can orchestrate the movement of large scale data (amounts or files) from on-premises NAS/SAN into AWS or vice-versa. Used for migrations, data processing transfers, archival/cost effective storage or DR/BC, designed to work at huge scale. Keeps metadata (e.g. permissions/timestamps). Built-in data validation.

- Scalable - 10Gbps per agent (~100TB per day)
- Bandwidth limiters to avoid link saturation
- Incremental and scheduled transfer options
- Compression and encryption
- Automatic recovery from transit errors
- AWS service integration - S3, EFS, FSx.
- Pay as you use, per GB cost for data moved.

DataSync Components:

- Task - A 'job' within DataSync, defined what is being synced, how quickly, FROM where and TO where.
- Agent - Software used to read or write to on-premises data stores using NFS or SMB.
- Location - Every task has two location FROM and TO. E.g. Network File System (NFS), Server Message Block (SMB), Amazon EFS, Amazon FSx and Amazon S3.

**FSx for Windows Servers** provides a native windows file system as a service which can be used within AWS, or from on-premises environments via VPN or Direct Connect FSx is an advanced shared file system accessible over SMB, and integrates with Active Directory (either managed, or self-hosted). It provides advanced features such as VSS, Data de-duplication, backups, encryption at rest and forced encryption in transit. Can be deployed as single or multi-AZ within a VPN. Can perform on-demand and scheduled backup.

![](https://s1ngh.ca/images/BFvJKNk7aaph0Ots-image-1640323164836.png)

- VSS - User-Driver Restores.
- Native file system accessible over SMB.
- Uses Windows Permission model.
- Supports DFS. Scale-out file share structure.
- Managed - no file server admin.
- Integrates with DS and self-managed directory.

**FSx for Lustre** is a managed file system which uses the FSx product designed for high performance computing. It delivers extreme performance for scenarios such as Big Data, Machine Learning and Financial Modeling. Managed Lustre - Designed for HPC - LINUX Client(POSIX).

- Persistent - Longer Term, HA(in one AZ), self-healing
- Scratch - Highly optimized for short term no replication &amp; fast. Pure performance. No HA, no replication.

Both can be backed up to S3, manual or Automatic 0-35 day retention.

Metadata stored on Metadata Targets(MDTs). Objects are stored on called object storage targets (OSTs) (1.17TiB). Baseline performance based on size. Size - min 1.2.TiB then increments of 2.4TiB. For Scratch - Base 200MB/s per TiB of storage. Persistent offers 50MB/s, 100MB/s and 200MB/s per TiB of storage. Burst up to 1300MB/s per TiB (Credit system).

![](https://s1ngh.ca/images/9tCKRhWhA8hHFcKv-image-1640324195009.png)

## **Security, Deployment &amp; Operations**

**AWS Secrets manager** is a product which can manage secrets within AWS. There is some overlap between it and the SSM Parameter Store - but Secrets manager is specialized for secrets(passwords, API Keys). Additionally Secrets manager is capable of automatic credential rotation using Lambda. For supported services it can even adjust the credentials of the service itself.

**AWS Shield** and **Web Application Firewall (WAF)** are both products which provide perimeter defense for AWS networks. Shield provides DDOS protection against layer 3 and layer 4 attacks. and WAF is a Layer 7 Application Firewall.

Shield Standard - free with Route53 and CloudFront.

Shield Advanced -Protects additional resources, EC2, ELB, CloudFront, Global Accelerator &amp; R53. Also provides a DDoS response team &amp; financial insurance.

WAF Web Access Control List (WEBACL) integrated with ALB, API Gateway and CloudFront. Rules are added to a WEBACL and evaluated when traffic arrives.

![](https://s1ngh.ca/images/yzmfu3d15I53xuNf-image-1640360794093.png)

**CloudHSM** - an AWS provided Hardware Security Module product. CloudHSM is required to achieve compliance with certain security standards such as FIPS 140-2 Level 3

- WIth KMS - AWS Managed servie. Shared service but separated. On the back-end KMS uses HSM. KMS is FIPS 140-2 Level 2 overall.
- CloudHSM - True 'Single Tenant' Hardware Security Module (HSM).
- CloudHSM is AWS provisioned but fully customer managed.
- For KMS, all operations are performed through AWS APIs.
- CloudHSM can be managed using industry standard APIs - PKCS#11, Java Cryptography Extensions (JCE), Microsoft CryptoNG(CNG) libraries.
- KMS can use CloudHSM as a custom key store, CloudHSM integrates with KMS.

CloudHSM is deployed into an AWS managed VPC.

![](https://s1ngh.ca/images/OAB6OceXTF6OUhLq-image-1640361365736.png)

- CloudHSM no native AWS integration, such as no S3 SSE.
- Can be used for offloading SSL/TLS processing for web servers.
- Use for enabling Transparent Data Encryption(TDE) for Oracle Databases.
- Use for protecting private keys for an issuing CA.

**AWS Config** is a service which records the configuration of resources over time (configuration items) into configuration histories. All the information is stored regionally in an S3 config bucket. AWS Config is capable of checking for compliance .. and generating SNS notifications and events via EventBridge &amp; Lambda based on compliance. **It does not prevent changes happening.** it is a regional service, supporting cross-region and account aggregation.

![](https://s1ngh.ca/images/rznxf2NoSA28NSUi-image-1640361848903.png)

**Amazon Macie** is a fully managed data security and data privacy service that uses machine learning and pattern matching to discover and protect your sensitive data in AWS.

- Discover, Monitor and Protect Data stored in S3 buckets.
- Automate discovery of data, i.e., PII, PHI, Finance.
- Managed Data Identifiers - Built-in - ML/Patterns. Maintained by AWS and has a growing list of common sensitive data types.
- Custom Data Identifiers - Proprietary - Regex Based. Useful for data patterns that are custom to application. Can use keywords, maximum match distance and ignore word to enhance pattern matching.
- Integrated with Security Hub &amp; finding events to EventBridge
- Centrally managed via AWS ORG or one Macie Account Inviting.
- Policy Findings are generated when policies or settings of an S3 bucket are changed in way that it reduces it's security.
- Sensitive data findings are discovered through data pattern matching.

![](https://s1ngh.ca/images/DDQr1uI4qYCcciwu-image-1640362173239.png)

**Amazon Inspector** is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS. Amazon Inspector automatically assesses applications for exposure, vulnerabilities, and deviations from best practices on EC2 instances &amp; the instance OS. Provides a report of findings ordered by priority.

- Network Assessment (Agentless)
- Network &amp; Host Assessment (Agent)

Rules packages determine what is checked.

- Network Reachability (no agent required) - Check reachability end to end from public networks and identifies ports that are listening. Using agents provides additional OS visibility.
- Packages - Host Assessments(Agent required). CVE package. CIS Benchmarks package. Security best practices for Amazon Inspector package.

**Guard Duty** is an automatic threat detection service which reviews data from supported services and attempts to identify any events outside of the 'norm' for a given AWS account or Accounts. It utilizes AI/ML, plus threat intelligence feeds to identify unexpected and unauthorized activity. Supports multiple accounts (Master and member).

![](https://s1ngh.ca/images/WWiD8gAbbEbKXHos-image-1640363038086.png)

## **Infrastructure as Code (CloudFormation)**

- CloudFormation Template - YAML or JSON 
    - Contains logical resources - the WHAT
- Templates are used to create Stacks
- Stacks create physical resources from the logical.
- If a stacks template is change, physical resources are changed.
- If a stack is deleted, normally, the physical resources are deleted.

**Template** and **Pseudo Parameters** are two methods to provide input to a template, which can influence what resources are provisioned, and the configuration of those resources.

Template parameters accept input from console/CLI/API. These can be referenced from within logical resources and influence physical resources and configuration. Can be configured with Defaults, AllowedValues, Minx and Max length &amp; AllowedPatterns, NoEcho &amp; Type. Pseudo Paramters are injected by AWS, eg. AWS::Region.

AWS CloudFormation provides several built-in functions that help manage stacks. Use intrinsic functions in your templates to assign values to properties that are not available until runtime.

- Ref &amp; Fn::GetAtt - To reference value from one logical resource or parameter to another one.
- Fn::Join &amp; Fn::Split - Join or split strings
- Fn::GetAZs &amp; Fn::Select - Get list of AZs for given region and select one of them.
- Conditions (Fn:: IF, And, Equals, Not &amp; Or)
- Fn::Base64 &amp; Fn::Sub - Encodes text into Base64. Sub allows performing replacements on variables.
- Fn::Cidr - Builds CIDR block for networking.

The optional `Mappings` section matches a key to a corresponding set of named values. For example, if you want to set values based on a region, you can create a mapping that uses the region name as a key and contains the values you want to specify for each specific region. The `Fn::FindInMap` intrinsic function retrieves values in a map. Common use case to map AMI list for region.

The optional `Outputs` section declares output values that can be imported into other stacks (to create cross-stack references), return in response (to describe stack calls), or viewed on the AWS CloudFormation console. For example, you can output the S3 bucket name for a stack to make the bucket easier to find. Accessible from a parent stack when using nesting. Can be exported, allowing cross-stack references.

SSM also provides a list of parameters that can be used in a CF template.

- Attempt to make a template without explicit naming
- Use Parameters with default values.
- Utilize features to dynamically reference fields.

The optional `Conditions` section contains statements that define the circumstances under which entities are created or configured. You might use conditions when you want to reuse a template that can create resources in different contexts, such as a test environment versus a production environment. In your template, you can add an `EnvironmentType` input parameter, which accepts either `<strong>prod</strong>` or `<strong>test</strong>` as inputs. Conditions are evaluated based on predefined pseudo parameters or input parameter values that you specify when you create or update a stack. Within each condition, you can reference another condition, a parameter value, or a mapping. After you define all your conditions, you can associate them with resources and resource properties in the `Resources` and `Outputs` sections of a template. Each condition is evaluated TRUE or FALSE. These are processed before resources are created. Uses other intrinsic functions which are associated with logical resources to control if they are created or not.

With the `DependsOn` attribute you can specify that the creation of a specific resource follows another. When you add a `DependsOn` attribute to a resource, that resource is created only after the creation of the resource specified in the `DependsOn` attribute. CloudFormation does things in parallel and tries to determine a dependency order. Example, an elastic IP requires an IGW attached to a VPC in order to work, but there is no reference in the template normally. Can specify a single resource or a list of resources.

**CreationPolicy**, **WaitConditions** and **cfn-signal** can all be used together to prevent the status of a resource from reaching create complete until AWS CloudFormation receives a specified number of success signals or the timeout period is exceeded. The cfn-signal helper script signals AWS CloudFormation to indicate whether Amazon EC2 instances have been successfully created or updated.

With CloudFormation Signal:

- Configure CF to hold and wait for 'x' number of success signals.
- Wait for Timeout for those signals (12 hour max)
- If success signals received .. CREATE\_COMPLETE.
- If failure signal received .. creation fails.
- If timeout is reached .. creation fails.

CreationPolicy should be used for provisioning EC2 and ASG. WaitCondition may be used when external systems need to be signaled.

WaitCondition is a specific logical resource.

**Nested stacks** allow for a hierarchy of related templates to be combined to form a single product. A root stack can contain and create nested stacks .. each of which can be passed parameters and provide back outputs. Nested stacks should be used when the resources being provisioned share a lifecycle and are related. There is a limit of 500 resources in one stack. Root stack is the only stack that is created manually.

- Use Nested Stacks to overcome limit of 500resources per stack.
- Modular templates, code reuse.
- Make the installation process easier.
- **Use Nested stacks when everything is lifecycle linked.**

**Cross stack** references allow one stack to reference another. CloudFormation stacks are designed to be isolated and self-contained. Outputs are normally not visible from other stacks. Root stacks can reference the output of nested stacks. Outputs can be exported, making them visible from other stacks. Exports must have a unique name in the region. Outputs in one stack reference logical resources or attributes in that stack. They can be exported, and then using the !ImportValue intrinsic function, referenced from another stack. Cross-region/Cross-account is not supported.

**StackSets** are a feature of CloudFormation allowing infrastructure to be deployed and managed across multiple regions and multiple accounts from a single location. Additionally it adds a dynamic architecture - allowing automatic operations based on accounts being added or removed from the scope of a StackSet. StackSets are containers in an admin account, containing stack instances, which reference stacks. Stack instances &amp; stacks are in target accounts. Each stack runs in 1 region and 1 account.

- Concurrent Accounts - How many accounts can be deployed into at one time.
- Failure Tolerance - Amount of individual deployments that can fail before the StackSet is considered failed.
- Retain Stacks
- Enable AWS Config
- Use for creating AWS Config Rules, IAM Roles.

With the **DeletionPolicy** attribute you can preserve or (in some cases) backup a resource when its stack is deleted. You specify a DeletionPolicy attribute for each resource that you want to control. If a resource has no DeletionPolicy attribute, AWS CloudFormation deletes the resource by default. Can specify to Delete, Retain or Snapshot(if supported --&gt; EBS volume, ElastiCache, Neptune, RDS, Redshift). DeletionPolicy only applies to DELETE not REPLACE.

**Stack roles** allow an IAM role to be passed into the stack via PassRole. A stack uses this role, rather than the identity interacting with the stack to create, update and delete AWS resources. It allows role separation and is a powerful security feature. By default, CFN uses the permissions of the logged in identity. CFN can assume a role to gain the permissions, this allows implementing role separation. The identity creating the stack doesn't need resource permissions only PassRole.

**CloudFormationInit** and **cfn-init** are tools which allow a desired state configuration management system to be implemented within CloudFormation. Use the AWS::CloudFormation::Init type to include metadata on an Amazon EC2 instance for the cfn-init helper script. If your template calls the cfn-init script, the script looks for resource metadata rooted in the AWS::CloudFormation::Init metadata key. cfn-init supports all metadata types for Linux systems &amp; It supports some metadata types for Windows. configSets define which configkeys to use and in which order to apply. Configset is supplied to cfn-init.

cfn-intit is only run once as part of bootstrapping. The **cfn-hup** helper is a daemon that detects changes in resource metadata and runs user-specified actions when a change is detected. This allows you to make configuration updates on your running Amazon EC2 instances through the UpdateStack API action.

**cloud-init** files contain output of user-data. **cfn-init** files contain output of the cfn-init operation.

When you need to update a stack, understanding how your changes will affect running resources before you implement them can help you update stacks with confidence. When a stack update is performed, there may be no interruption, some interruption or Replacement. **Change sets** allow you to preview how proposed changes to a stack might impact your running resources, for example, whether your changes will delete or replace any critical resources, AWS CloudFormation makes the changes to your stack only when you decide to execute the change set, allowing you to decide whether to proceed with your proposed changes or explore other changes by creating another change set.

**Custom resources** enable you to write custom provisioning logic in templates that AWS CloudFormation runs anytime you create, update (if you changed the custom resource), or delete stacks. Custom resources let CFN integrate with anything it doesn't yet, or doesn't natively support. To implement Custom Resources, CFN passes data to something, gets data back from something.

CloudFormation is unable to delete a modified S3 bucket. It can be achieved using custom resource.

## **NoSQL Databases &amp; DynamoDB**

DynamoDB is a NoSQL fully managed Database-as-a-Service (DBaaS) product available within AWS. It can handle Key/Value &amp; Document data. Manual/Automatic provisioned performance IN/OUT or On-Demand. Highly resilient, across AZs and optionally global. Single-digit milliseconds access. Supports backups, point-in-time recovery, encryption at rest, and event-driven integration.

Items can be considered as Rows of an RDS.

![](https://s1ngh.ca/images/AswXCZtFCL0aVmXD-image-1640459883549.png)

![](https://s1ngh.ca/images/lrSHtDnlII40LSdY-image-1640459913893.png)

- NoSQL - preference DynamoDB.
- Relational Data - generally not DynamoDB.
- Key/Value - preference DynamoDB.
- Access via console, CLI, API. There's no SQL for DynamoDB.
- Billed based on RCU, WCU, Storage and features.

Capacity Modes:

- On-Demand - unknown, unpredictable, low admin. Price per million R or W units.
- Provisioned - RCU and WCU set on a per table basis. Every operation consumes at least 1 RCU/WCU.

1 RCU is 1x4KB read operation per second. 1 WCU is 1x1KB write operation per second. Every table has a RCU and WCU burst pool (300 seconds).

With DynamoDB every piece of data is replicated multiple times into separate Availability Zones, called Storage Nodes.

Eventually consistent reads are half the price of strongly consistent reads, it selects one of the storage nodes for reads. Strong consistent reads connect to leader node to get the most up to date copy of data.

WCU Calculation - Identify the WCU per item then multiply by average number of items per second.

RCU Calculation - Identify the RCU per item then multiple by average read operations per second. For eventually consistent,50% of strongly consistent RCU.

**Local Secondary Indexes (LSI)** and **Global Secondary Indexes (GSI)** allow for an alternative presentation of data stored in a base table.

Query can only work on 1 PK value at a time and optionally a single, or range of SK values. Indexes are alternative views on table data. LSI allow for alternative SK's whereas with GSIs you can use alternative PK and SK.

LSI must be created with a table, 5 LSI's per base table. LSI shared the RCU and WCU with the table. Attributes - ALL, KEYS\_ONLY &amp; INCLUDE.

GSI can be created at any time. Default limit of 20 per base table. Alternative PK and SK. GSI's have their own RCU and WCU allocations. Attributes - ALL, KEYS\_ONLY &amp; INCLUDE.

- Careful with projection.
- Queries on attributes NOT projected are expensive.
- Use GSIs as default, LSI only when strong consistency is required.
- Use indexes for alternative access patterns.

DynamoDB Streams are a 24 hour rolling window of time ordered changes to ITEMS in a DynamoDB table. Behind the scenes it uses Kinesis streams. Records INSERTS, UPDATES and DELETES. Streams have to be enabled on a per table basis , and have 4 view types:

- KEYS\_ONLY - Stream only records the PK and optionally any applicable SK.
- NEW\_IMAGE - Entire item in the state after the change.
- OLD\_IMAGE- Entire item in the state before the change.
- NEW\_AND\_OLD\_IMAGES - Stores the pre-change and post-change state.

Lambda can be integrated to provide trigger functionality - invoking when new entries are added on the stream. ITEM change generates an event. The event contains the data which changed and an action is taken using that data.

Streams and Triggers are useful for reporting and analytics. Also useful for aggregation, messaging or notifications.

**DynamoDB Global Tables** provides multi-master global replication of DynamoDB tables which can be used for performance, HA or DR/BC reasons. Tables are created in multiple regions and added to the same global table (becoming replica tables). Last writer wins is used for conflict resolution. Reads and Write can occur to any region. Generally sub-second replication between regions. Strong consistent reads ONLY in the same region as writes. Cross-region is eventually consistent.

**DynamoDB Accelerator (DAX)** is an in-memory cache designed specifically for DynamoDB. It should be the default choice for any DynamoDB caching related questions.

![](https://s1ngh.ca/images/ZmX8Fu1kFPdFV4ez-image-1640464881704.png)

- DAX has primary nodes(Writes) and Replcias(Read).
- Nodes are HA, primary failure leads to re-election.
- In-Memory cache - Scaling, much faster reads, reduces costs.
- Can Scale UP and Scale OUT.
- Supports write-through.
- DAX Deployed within a VPC.

DAX is not ideal for strongly consistent reads or write-heavy environments.

**Amazon Athena** is serverless querying service which allows for ad-hoc queries where billing is based on the amount of data consumed. Athena is an underrated service capable of working with unstructured, semi-structured or structured data. Athena uses process of Schema-on-read. **Original data is never changed - remains on S3**. Schema translates data on the fly into a relational-like structure upon read. Output can be sent to other services.

**Elasticache** is a managed in-memory cache which provides a managed implementation of the **redis** or **memcached** engines. It is useful for read heavy workloads, scaling reads in a cost effective way and allowing for externally hosted user session state. Reduces database workloads(cost-effective). Can be used to store session data (stateless servers). Requires application code changes.

![](https://s1ngh.ca/images/TdtF3yf5fiLz0my1-image-1640467169998.png)

![](https://s1ngh.ca/images/7m91he7RXsX2eYLb-image-1640467283392.png)

Memcached - Simple data structures. No replication. Multiple Nodes (Sharding). No backups. Multi-threaded.

Redis - Advanced Structures. Multi-AZ replication. Replication across instances (Scale Reads). Backup &amp; Restore. Transactions.

**Redshift** is a column based, petabyte scale, data warehousing product within AWS. Its designed for OLAP(Column based) products within AWS/on-premises to add data to for long term processing, aggregation and trending. Direct query S3 using Redshift Spectrum. Direct Query other DBs using federated query. Integrates with AWS tooling such as Quicksight. SQL-Like interface JDBC/ODBC connections.

- Server based (not serverless).
- One AZ in a VPC.
- Cluster has a leader node, query input, planning and aggregation. Manages distributing data to the computer nodes.
- Compute nodes - performing queries of data, assigned by leader node.
- VPC Security, IAM permissions, KMS at rest encryption, CW monitoring.
- Redshift Enhanced VPC Routing - follows VPC networking.

![](https://s1ngh.ca/images/GOzTST79QLiPm9Mx-image-1640468048901.png)

![](https://s1ngh.ca/images/UQF7tf5CxvamoF47-image-1640468221430.png)
